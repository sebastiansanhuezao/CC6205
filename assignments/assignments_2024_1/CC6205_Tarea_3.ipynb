{
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "NXgaywGdo0bh",
        "YWEFCu4_sWwm",
        "eN984Z0XzHkP",
        "F2bRYNRnKRzK",
        "QwdOcPfbL3pH",
        "Gkn38sTsdpzR",
        "Q5dlEgEqdtvp",
        "37IjYq-_d5Pv",
        "pURRQLkReNMY",
        "JIFrDPaGej4y",
        "M-dsNSEdej4z",
        "PKZIGOUpej4z",
        "epaoMVyMej40",
        "bqymD_Nuej41",
        "ZcPtyefAenbW",
        "eYUFyLMJenbX",
        "800wWbuGenbY",
        "DYBzB3SlenbZ",
        "YxQkQt1Benba",
        "ETvk1QHuC-Gs"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30733,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tarea 3: Sequence Labelling\n",
        "**Procesamiento de Lenguaje Natural (CC6205-1 - Oto침o 2024)**"
      ],
      "metadata": {
        "id": "AxrkZWMLZB8z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tarjeta de identificaci칩n\n",
        "\n",
        "**Nombres:** ```Mart칤n Reyes - Sebasti치n Sanhueza```\n",
        "\n",
        "**Fecha l칤mite de entrega 游늱:** 06/06.\n",
        "\n",
        "**Tiempo estimado de dedicaci칩n:** 4 horas\n"
      ],
      "metadata": {
        "id": "b97b4IJjZGxM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instrucciones\n",
        "Bienvenid@s a la tercera tarea en el curso de Natural Language Processing (NLP). Esta tarea tiene como objetivo evaluar los contenidos te칩ricos de las 칰ltimas semanas de clases posteriores a la tarea 2, enfocado principalmente en **Word Embeddings**, **Sequence Labeling - HMM**, **Convolutional Neural Networks** y **Recurrent Neural Networks**. Si a칰n no has visto las clases, se recomienda visitar los links de las referencias.\n",
        "\n",
        "La tarea consta de una una parte pr치ctica con el f칤n de introducirlos a la programaci칩n en Python enfocada en NLP.\n",
        "\n",
        "* La tarea es en **grupo** (maximo hasta 3 personas).\n",
        "* La entrega es a trav칠s de u-cursos a m치s tardar el d칤a estipulado arriba. No se aceptan atrasos.\n",
        "* El formato de entrega es este mismo Jupyter Notebook.\n",
        "* Al momento de la revisi칩n su c칩digo ser치 ejecutado. Por favor verifiquen que su entrega no tenga errores de compilaci칩n.\n",
        "* Completar la tarjeta de identificaci칩n. Sin ella no podr치 tener nota."
      ],
      "metadata": {
        "id": "TKcZMFlmZ3b9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Material de referencia\n",
        "\n",
        "Diapositivas del curso 游늯\n",
        "    \n",
        "- [Word Embeddings](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-wordvectors.pdf)\n",
        "- [Sequence Labeling - HMM](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-HMM.pdf)\n",
        "- [Convolutional Neural Networks](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-CNN.pdf)\n",
        "- [Recurrent Neural Networks](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-RNN.pdf)\n",
        "\n",
        "Videos del curso 游닠\n",
        "\n",
        "- Word Embeddings: [Parte 1](https://www.youtube.com/watch?v=wtwUsJMC9CA), [Parte 2](https://www.youtube.com/watch?v=XDxzQ7JU95U), [Parte 3](https://www.youtube.com/watch?v=Ikyc3DRVodk)\n",
        "\n",
        "- Sequence Labeling - HMM: [Parte 1](https://www.youtube.com/watch?v=-ngfOZz8yK0), [Parte 2](https://www.youtube.com/watch?v=Tjgb-yQOg54), [Parte 3](https://www.youtube.com/watch?v=aaa5Qoi8Vco), [Parte 4](https://www.youtube.com/watch?v=4pKWIDkF_6Y)\n",
        "\n",
        "- [Convolutional Neural Networks](https://www.youtube.com/watch?v=lLZW5Fn40r8)\n",
        "\n",
        "- Recurrent Neural Networks: [Parte 1](https://www.youtube.com/watch?v=BmhjUkzz3nk), [Parte 2](https://www.youtube.com/watch?v=z43YFR1iIvk), [Parte 3](https://youtu.be/7L5JxQdwNJk)"
      ],
      "metadata": {
        "id": "dnTrhOKraAw2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objetivo\n",
        "\n",
        "El objetivo de esta tarea es resolver una de las tareas m치s importantes en el 치rea del procesamiento de lenguage natural, relacionada con la extracci칩n de informaci칩n: [Named Entity Recognition (NER)](http://www.cs.columbia.edu/~mcollins/cs4705-spring2019/slides/tagging.pdf).\n",
        "\n",
        "En particular, deber치n crear distintos modelos que apunten a resolver la tarea de NER en Espa침ol. Para esto, les entregaremos un dataset real perteneciente a la lista de espera NO GES en Chile. Es importante destacar que existe una falta de trabajos realizados en el 치rea de NER en Espa침ol y a칰n m치s en el contexto cl칤nico, por ende puede ser considerado como una tarea bien desafiante y quiz치s les interesa trabajar en el 치rea m치s adelante en sus carreras.\n",
        "\n",
        "En este notebook les entregaremos un baseline como referencia de los resultados que esperamos puedan obtener. Recuerden que el no superar a los baselines en alguna de las tres m칠tricas conlleva un descuento de 0.5 puntos hasta 1.5 puntos.\n",
        "\n",
        "Como hemos estado viendo redes neuronales tanto en c치tedras, tareas y auxiliares (o pr칩ximamente lo har치n), esperamos que (por lo menos) utilicen Redes Neuronales Recurrentes (RNN) para resolverla.\n",
        "\n",
        "Nuevamente, hay total libertad para utilizar el software y los modelos que deseen, siempre y cuando estos no traigan los modelos ya implementados (de todas maneras, como es un corpus nuevo, es dif칤cil que haya alg칰n modelo ya implementado con 칠stas entidades)."
      ],
      "metadata": {
        "id": "025o3RYmm3oM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explicaci칩n de NER\n",
        "\n",
        "En esta tarea van a resolver **NER**, com칰nmente abordada como un problema de Sequence Labeling.\n",
        "\n",
        "**쯈u칠 es Sequence Labeling?**\n",
        "\n",
        "En breves palabras, dada una secuencia de tokens (oraci칩n) sequence labeling tiene por objetivo asignar una etiqueta a cada token de dicha secuencia. En pocas palabras, dada una lista de tokens esperamos encontrar la mejor secuencia de etiquetas asociadas a esa lista. Ahora veamos de qu칠 se trata este problema.\n",
        "\n",
        "**Named Entity Recognition (NER)**\n",
        "\n",
        "NER es un ejemplo de un problema de Sequence Labeling. Pero antes de definir formalmente esta tarea, es necesario definir algunos conceptos claves para poder entenderla de la mejor manera:\n",
        "\n",
        "- *Token*: Un token es una secuencia de caracteres, puede ser una palabra, un n칰mero o un s칤mbolo.\n",
        "\n",
        "- *Entidad*: No es m치s que un trozo de texto (uno o m치s tokens) asociado a una categor칤a predefinida. Originalmente se sol칤an utilizar categor칤as como nombres de personas, organizaciones, ubicaciones, pero actualmente se ha extendido a diferentes dominios.\n",
        "\n",
        "- *L칤mites de una entidad*: Son los 칤ndices de los tokens de inicio y f칤n dentro de una entidad.\n",
        "\n",
        "- *Tipo de entidad*: Es la categor칤a predefinida asociada a la entidad.\n",
        "\n",
        "Dicho esto, definimos formalmente una entidad como una tupla: $(s, e, t)$, donde $s, t$ son los l칤mites de la entidad (칤ndices de los tokens de inicio y fin, respectivamente) y corresponde al tipo de entidad o categor칤a. Ya veremos m치s ejemplos luego de describir el Dataset.\n",
        "\n",
        "**Corpus de la Lista de espera**\n",
        "\n",
        "Trabajaran con un conjunto de datos reales correspondiente a interconsultas de la lista de espera NO GES en Chile. Si quieren saber m치s sobre c칩mo fueron generados los datos pueden revisar el paper publicado hace unos meses atr치s en el workshop de EMNLP, una de las conferencias m치s importantes de NLP: [https://www.aclweb.org/anthology/2020.clinicalnlp-1.32/](https://www.aclweb.org/anthology/2020.clinicalnlp-1.32/).\n",
        "\n",
        "Este corpus Chileno est치 constituido originalmente por 7 tipos de entidades pero por simplicidad en esta tarea trabajar치n con las siguientes:\n",
        "\n",
        "- **Disease**\n",
        "- **Body_Part**\n",
        "- **Medication**\n",
        "- **Procedures**\n",
        "- **Family_Member**\n",
        "\n",
        "Si quieren obtener m치s informaci칩n sobre estas entidades pueden consultar la [gu칤a de anotaci칩n](https://plncmm.github.io/annodoc/). Adem치s, mencionar que este corpus est치 restringido bajo una licencia que permite solamente su uso acad칠mico, as칤 que no puede ser compartido m치s all치 de este curso o sin permisos por parte de los autores en caso que quieran utilizarlo fuera. Si este 칰ltimo es el caso entonces pueden escribir directamente al correo: pln@cmm.uchile.cl. Al aceptar los t칠rminos y condiciones de la tarea est치n de acuerdo con los puntos descritos anteriormente.\n",
        "\n",
        "\n",
        "**Formato ConLL**\n",
        "\n",
        "Los archivos que ser치n entregados a ustedes vienen en un formato est치ndar utilizado en NER, llamado ConLL. No es m치s que un archivo de texto, que cumple las siguientes propiedades.\n",
        "\n",
        "- Un salto de linea corresponde a la separaci칩n entre oraciones. Esto es importante ya que al entrenar una red neuronal ustedes pasaran una lista de oraciones como input, m치s conocidos como batches.\n",
        "\n",
        "- La primera columna del archivo contiene todos los tokens de la partici칩n.\n",
        "\n",
        "- La segunda columna del archivo contiene el tipo de entidad asociado al token de la primera columna.\n",
        "\n",
        "- Los tipos de entidades siguen un formato cl치sico en NER denominado *IOB2*. Si un tipo de entidad comienza con el prefijo \"B-\" (Beginning) significa que es el token de inicio de una entidad, si comienza con \"I-\" (Inside) es un token distinto al de inicio y si un token est치 asociado a la categor칤a O (Outside) significa que no pertenece a ninguna entidad.\n",
        "\n",
        "Aqu칤 va un ejemplo:\n",
        "\n",
        "```\n",
        "PACIENTE O\n",
        "PRESENTA O\n",
        "FRACTURA B-Disease\n",
        "CORONARIA I-Disease\n",
        "COMPLICADA I-Disease\n",
        "EN O\n",
        "PIE B-Body_Part\n",
        "IZQUIERDO I-Body_Part\n",
        ". O\n",
        "SE O\n",
        "REALIZA O\n",
        "INSTRUMENTACION B-Procedure\n",
        "INTRACONDUCTO I-Procedure\n",
        ". O\n",
        "```\n",
        "\n",
        "Seg칰n nuestra definici칩n tenemos las siguientes tres entidades (enumerando desde 0):\n",
        "\n",
        "- $(2, 4, Disease)$\n",
        "- $(6, 7, Body Part)$\n",
        "- $(11, 12, Procedure)$\n",
        "\n",
        "Repasen un par de veces todos estos conceptos antes de pasar a la siguiente secci칩n del notebook.\n",
        "Es importante entender bien este formato ya que al medir el rendimiento de sus modelos, consideraremos una **m칠trica estricta**. Esta m칠trica se llama as칤 ya que considera correcta una predicci칩n de su modelo, s칩lo si al compararlo con las entidades reales **coinciden tanto los l칤mites de la entidad como el tipo.**\n",
        "\n",
        "Para ejemplificar, tomando el caso anterior, si el modelo es capaz de encontrar la siguiente entidad: $(2, 3, Disease)$, entonces se considera incorrecto ya que pudo predecir dos de los tres tokens de dicha enfermedad. Es decir, buscamos una m칠trica que sea alta a nivel de entidad y no a nivel de token.\n",
        "\n",
        "Antes de pasar a explicar las reglas, se recomienda visitar los siguientes links para entender bien el baseline de la tarea:\n",
        "\n",
        "-  [Recurrent Neural Networks](slides/NLP-RNN.pdf): [Parte 1](https://youtu.be/BmhjUkzz3nk), [Parte 2](https://youtu.be/z43YFR1iIvk), [Parte 3](https://youtu.be/7L5JxQdwNJk)\n",
        "\n",
        "\n",
        "Recuerden que todo el material se encuentra disponible en el [github del curso](https://github.com/dccuchile/CC6205)."
      ],
      "metadata": {
        "id": "KbBq7gcHnPTf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline\n",
        "\n",
        "En este punto esperamos que tengan conocimiento sobre redes neuronales y en particular redes neuronales recurrentes (RNN), si no siempre pueden escribirnos por el canal de Discord para aclarar dudas. La RNN del baseline adjunto a este notebook est치 programado en la librer칤a [`pytorch`](https://pytorch.org/) pero ustedes pueden utilizar keras, tensorflow si as칤 lo desean. El c칩digo contiene lo siguiente:\n",
        "\n",
        "- La carga de los datasets, creaci칩n de batches de texto y padding (esto es importante ya que si utilizan redes neuronales tienen que tener el mismo largo los inputs).\n",
        "\n",
        "- La implementaci칩n b치sica de una red `LSTM` simple de solo un nivel y sin bi-direccionalidad.\n",
        "\n",
        "- La construcci칩n del formato del output requerido para que lo puedan probar en la tarea en codalab."
      ],
      "metadata": {
        "id": "NXgaywGdo0bh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Sugerencias**\n",
        "Se espera que ustedes puedan experimentar con el baseline utilizando (pero no limit치ndose) estas sugerencias:\n",
        "\n",
        "*   Probar la t칠cnica de early stopping.\n",
        "*   Variar la cantidad de par치metros de la capa de embeddings.\n",
        "*   Variar la cantidad de capas RNN.\n",
        "*   Variar la cantidad de par치metros de las capas de RNN.\n",
        "*   Inicializar la capa de embeddings con modelos pre-entrenados. (word2vec, glove, conceptnet, etc...). [Embeddings en espa침ol aqu칤](https://github.com/dccuchile/spanish-word-embeddings). Tambi칠n aqu칤 pueden encontrar unos embeddings cl칤nicos en Espa침ol: [https://zenodo.org/record/3924799](https://zenodo.org/record/3924799)\n",
        "*   Variar la cantidad de 칠pocas de entrenamiento.\n",
        "*   Variar el optimizador, learning rate, batch size, etc.\n",
        "*   Probar bi-direccionalidad.\n",
        "*   Incluir dropout.\n",
        "*   Probar modelos de tipo GRU.\n",
        "*   Probar usando capas de atenci칩n.\n",
        "*   Probar Embedding Contextuales (les puede ser de utilidad [flair](https://github.com/flairNLP/flair))\n",
        "*   Probar modelos de transformers en espa침ol usando [Huggingface](https://github.com/huggingface/transformers) o el framework Flair."
      ],
      "metadata": {
        "id": "TfMlGTCgIq8o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experimento base\n",
        "\n",
        "El c칩digo que les entregaremos servir치 de baseline para luego implementar mejores modelos.\n",
        "En general, el c칩digo asociado a la carga de los datos, las funciones de entrenamiento, de evaluaci칩n y la predicci칩n de los datos de la tarea no deber칤an cambiar.\n",
        "Solo deben preocuparse de cambiar la arquitectura del modelo, sus hiperpar치metros y reportar, lo cual lo pueden hacer en las subsecciones *modelos*."
      ],
      "metadata": {
        "id": "YWEFCu4_sWwm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  **Carga de datos y Preprocesamiento**\n",
        "\n",
        "Para cargar los datos y preprocesarlos usaremos la librer칤a [`torchtext`](https://github.com/pytorch/text). Tener cuidado ya que hace algunos meses esta librer칤a tuvo cambios radicales, quedando las funcionalidades pasadas depreciadas de la librer칤a ```legacy```. Esto ya que si quieren usar m치s funciones de la librer칤a entonces vean los cambios en la documentaci칩n debe usar la versi칩n antigua con python 3.8\n",
        "\n",
        "El proceso ser치 el siguiente:\n",
        "\n",
        "1. Descargar los datos desde github y examinarlos.\n",
        "2. Cargar los datasets con la clase ```TaggingDataset``` de m치s abajo.\n",
        "3. Crear el vocabulario."
      ],
      "metadata": {
        "id": "_v9-YCA9sg-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install -U torchtext"
      ],
      "metadata": {
        "id": "YLZkrIVQsqBB",
        "execution": {
          "iopub.status.busy": "2024-06-12T07:44:53.767852Z",
          "iopub.execute_input": "2024-06-12T07:44:53.768645Z",
          "iopub.status.idle": "2024-06-12T07:48:51.472054Z",
          "shell.execute_reply.started": "2024-06-12T07:44:53.768597Z",
          "shell.execute_reply": "2024-06-12T07:48:51.470768Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchtext\n",
        "from torchtext import data, datasets\n",
        "\n",
        "# Garantizar reproducibilidad de los experimentos\n",
        "SEED = 1234\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4DCjj5bsxNJ",
        "outputId": "bd97bbe1-9e8c-4d02-be94-eb06b28683eb",
        "execution": {
          "iopub.status.busy": "2024-06-12T07:49:41.302677Z",
          "iopub.execute_input": "2024-06-12T07:49:41.303682Z",
          "iopub.status.idle": "2024-06-12T07:49:43.064934Z",
          "shell.execute_reply.started": "2024-06-12T07:49:41.303644Z",
          "shell.execute_reply": "2024-06-12T07:49:43.064043Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/torchtext/data/__init__.py:4: UserWarning: \n/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \nTorchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n/opt/conda/lib/python3.10/site-packages/torchtext/datasets/__init__.py:4: UserWarning: \n/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \nTorchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Obtener datos**\n",
        "\n",
        "Descargamos los datos de entrenamiento, validaci칩n y prueba en nuestro directorio de trabajo"
      ],
      "metadata": {
        "id": "TDCqI-1is2j_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "!wget https://github.com/dccuchile/CC6205/releases/download/v1.0/train.txt -nc\n",
        "!wget https://github.com/dccuchile/CC6205/releases/download/v1.0/dev.txt -nc"
      ],
      "metadata": {
        "id": "OIMlUsp3s7J-",
        "execution": {
          "iopub.status.busy": "2024-06-12T07:49:45.672846Z",
          "iopub.execute_input": "2024-06-12T07:49:45.673673Z",
          "iopub.status.idle": "2024-06-12T07:49:48.448781Z",
          "shell.execute_reply.started": "2024-06-12T07:49:45.673639Z",
          "shell.execute_reply": "2024-06-12T07:49:48.447668Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NUEVO DATALOADER Y OTRAS COSAS NECESARIAS\n",
        "from collections import Counter, OrderedDict\n",
        "\n",
        "import torch\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torchtext.vocab import vocab\n",
        "\n",
        "class TaggingDataset(Dataset):\n",
        "    def __init__(self, paths, lower=False, separator=\" \", encoding=\"utf-8\"):\n",
        "\n",
        "        data = []\n",
        "        for path in paths:\n",
        "          with open(path, 'r', encoding=encoding) as file:\n",
        "            text, tag = [], []\n",
        "            for line in file:\n",
        "                line = line.strip()\n",
        "                if line == \"\":\n",
        "                    data.append(dict({'text':text, 'nertags':tag}))\n",
        "                    text, tag = [], []\n",
        "                else:\n",
        "                    line_content = line.split(separator) # .rstrip('\\n')\n",
        "                    if lower:\n",
        "                      text.append(line_content[0].lower())\n",
        "                    else:\n",
        "                      text.append(line_content[0])\n",
        "                    tag.append(line_content[1])\n",
        "          data.append(dict({'text':text, 'nertags':tag}))\n",
        "\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        item = self.data[index]\n",
        "        text = item[\"text\"]\n",
        "        nertags = item[\"nertags\"]\n",
        "        return nertags, text\n",
        "\n",
        "def fit_vocab(data_iter):\n",
        "\n",
        "  def update_counter(counter_obj):\n",
        "    sorted_by_freq_tuples = sorted(counter_obj.items(),\n",
        "                                  key=lambda x: x[1],\n",
        "                                  reverse=True)\n",
        "    ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
        "    return ordered_dict\n",
        "\n",
        "  counter_1 = Counter()\n",
        "  counter_2 = Counter()\n",
        "  for _nertags, _text in data_iter:\n",
        "    counter_1.update(_text)\n",
        "    counter_2.update(_nertags)\n",
        "\n",
        "  od1 = update_counter(counter_1)\n",
        "  od2 = update_counter(counter_2)\n",
        "\n",
        "  v1 = vocab(od1, specials=['<PAD>', '<unk>'])\n",
        "  v1.set_default_index(v1[\"<unk>\"])\n",
        "  v2 = vocab(od2, specials=['<PAD>'])\n",
        "\n",
        "  text_pipeline = lambda x: v1(x)\n",
        "  nertags_pipeline = lambda x: v2(x)\n",
        "\n",
        "  return text_pipeline, nertags_pipeline, v1, v2\n",
        "\n",
        "def collate_batch(batch, nertags_pipeline, text_pipeline, device):\n",
        "  nertags_list, text_list = [], []\n",
        "  for _nertags, _text in batch:\n",
        "    processed_nertags = torch.tensor(nertags_pipeline(_nertags),\n",
        "                                     dtype=torch.int64)\n",
        "    nertags_list.append(processed_nertags)\n",
        "    processed_text = torch.tensor(text_pipeline(_text),\n",
        "                                  dtype=torch.int64)\n",
        "    text_list.append(processed_text)\n",
        "  nertags_list = pad_sequence(nertags_list, batch_first=True).T\n",
        "  text_list = pad_sequence(text_list, batch_first=True).T\n",
        "  return nertags_list.to(device), text_list.to(device)"
      ],
      "metadata": {
        "id": "kn_YMpyetNhn",
        "outputId": "5a60d941-fcde-4a6a-e44f-206061cab6b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.status.busy": "2024-06-12T07:49:54.731424Z",
          "iopub.execute_input": "2024-06-12T07:49:54.732302Z",
          "iopub.status.idle": "2024-06-12T07:49:54.852964Z",
          "shell.execute_reply.started": "2024-06-12T07:49:54.732264Z",
          "shell.execute_reply": "2024-06-12T07:49:54.852039Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/torchtext/vocab/__init__.py:4: UserWarning: \n/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \nTorchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n/opt/conda/lib/python3.10/site-packages/torchtext/utils.py:4: UserWarning: \n/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \nTorchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_iter = TaggingDataset([\"train.txt\", \"dev.txt\"])\n",
        "\n",
        "data_length = len(data_iter)\n",
        "\n",
        "train_length = int(data_length * 0.8)\n",
        "dev_length = int(data_length * 0.1)\n",
        "test_length = data_length - train_length - dev_length\n",
        "\n",
        "train_iter, dev_iter, test_iter = torch.utils.data.random_split(\n",
        "    data_iter,\n",
        "     (train_length, dev_length, test_length),\n",
        "    torch.Generator().manual_seed(42))\n",
        "\n",
        "text_pipeline, nertags_pipeline, TEXT, NER_TAGS = fit_vocab(train_iter)"
      ],
      "metadata": {
        "id": "ctd5gNmzxnnE",
        "execution": {
          "iopub.status.busy": "2024-06-12T07:50:01.492223Z",
          "iopub.execute_input": "2024-06-12T07:50:01.492614Z",
          "iopub.status.idle": "2024-06-12T07:50:01.898992Z",
          "shell.execute_reply.started": "2024-06-12T07:50:01.492583Z",
          "shell.execute_reply": "2024-06-12T07:50:01.898195Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_iter), len(dev_iter), len(test_iter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-MPvr5LDkq5",
        "outputId": "476226af-497f-4c18-8cfb-af56963c272e",
        "execution": {
          "iopub.status.busy": "2024-06-12T07:50:04.388005Z",
          "iopub.execute_input": "2024-06-12T07:50:04.388709Z",
          "iopub.status.idle": "2024-06-12T07:50:04.395613Z",
          "shell.execute_reply.started": "2024-06-12T07:50:04.388675Z",
          "shell.execute_reply": "2024-06-12T07:50:04.394815Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(7132, 891, 893)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# seteamos algunos valores de interes\n",
        "UNK_IDX = TEXT.vocab.get_stoi()['<unk>']\n",
        "PAD_IDX = TEXT.vocab.get_stoi()['<PAD>']\n",
        "\n",
        "PAD_TAG_IDX = NER_TAGS.get_stoi()['<PAD>']\n",
        "O_TAG_IDX = NER_TAGS.vocab.get_stoi()['O']"
      ],
      "metadata": {
        "id": "h-BjEO1exsuq",
        "execution": {
          "iopub.status.busy": "2024-06-12T07:50:07.892135Z",
          "iopub.execute_input": "2024-06-12T07:50:07.892756Z",
          "iopub.status.idle": "2024-06-12T07:50:07.920257Z",
          "shell.execute_reply.started": "2024-06-12T07:50:07.892721Z",
          "shell.execute_reply": "2024-06-12T07:50:07.919114Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 22\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using', device)\n",
        "\n",
        "fix_collocate_batch = lambda x: collate_batch(x, nertags_pipeline, text_pipeline, device)\n",
        "\n",
        "dataloader_train = DataLoader(\n",
        "    train_iter, batch_size=BATCH_SIZE, shuffle=False, collate_fn=fix_collocate_batch\n",
        ")\n",
        "dataloader_dev = DataLoader(\n",
        "    dev_iter, batch_size=BATCH_SIZE, shuffle=False, collate_fn=fix_collocate_batch\n",
        ")\n",
        "dataloader_test = DataLoader(\n",
        "    test_iter, batch_size=BATCH_SIZE, shuffle=False, collate_fn=fix_collocate_batch\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sD3AmVkOxsE8",
        "outputId": "72820ddd-e296-486f-f07c-a25d7479d40c",
        "execution": {
          "iopub.status.busy": "2024-06-12T07:50:10.378725Z",
          "iopub.execute_input": "2024-06-12T07:50:10.379073Z",
          "iopub.status.idle": "2024-06-12T07:50:10.46784Z",
          "shell.execute_reply.started": "2024-06-12T07:50:10.379044Z",
          "shell.execute_reply": "2024-06-12T07:50:10.466829Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Using cuda\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example = next(iter(dataloader_train))\n",
        "ner_tags_example = example[0]\n",
        "text_example = example[1]\n",
        "\n",
        "# revisamos el primer ejemplo\n",
        "[NER_TAGS.vocab.get_itos()[j] for j in ner_tags_example[:, 1]], [TEXT.vocab.get_itos()[j] for j in text_example[:, 1]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3XrV_YyyBWB",
        "outputId": "544855db-7beb-485f-9686-521e45129193",
        "execution": {
          "iopub.status.busy": "2024-06-12T07:50:12.545909Z",
          "iopub.execute_input": "2024-06-12T07:50:12.546755Z",
          "iopub.status.idle": "2024-06-12T07:50:12.813099Z",
          "shell.execute_reply.started": "2024-06-12T07:50:12.546711Z",
          "shell.execute_reply": "2024-06-12T07:50:12.811994Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 9,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(['O',\n  'O',\n  'O',\n  'O',\n  'B-Disease',\n  'I-Disease',\n  'I-Disease',\n  'I-Disease',\n  'O',\n  'O',\n  'O',\n  'O',\n  '<PAD>',\n  '<PAD>',\n  '<PAD>',\n  '<PAD>',\n  '<PAD>',\n  '<PAD>',\n  '<PAD>',\n  '<PAD>',\n  '<PAD>',\n  '<PAD>',\n  '<PAD>',\n  '<PAD>',\n  '<PAD>',\n  '<PAD>',\n  '<PAD>',\n  '<PAD>',\n  '<PAD>',\n  '<PAD>',\n  '<PAD>',\n  '<PAD>'],\n ['SOLICITO',\n  'EVALUACION',\n  'Y',\n  'TTO',\n  'SUBLUXACION',\n  'ATM',\n  'IZQ',\n  '.',\n  ',',\n  'DOLOR',\n  'APERTURA',\n  '.',\n  '<PAD>',\n  '<PAD>',\n  '<PAD>',\n  '<PAD>',\n  '<PAD>',\n  '<PAD>',\n  '<PAD>',\n  '<PAD>',\n  '<PAD>',\n  '<PAD>',\n  '<PAD>',\n  '<PAD>',\n  '<PAD>',\n  '<PAD>',\n  '<PAD>',\n  '<PAD>',\n  '<PAD>',\n  '<PAD>',\n  '<PAD>',\n  '<PAD>'])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install seqeval"
      ],
      "metadata": {
        "id": "9D81QD5Ky2_4",
        "execution": {
          "iopub.status.busy": "2024-06-12T07:50:16.513677Z",
          "iopub.execute_input": "2024-06-12T07:50:16.514031Z",
          "iopub.status.idle": "2024-06-12T07:50:32.443157Z",
          "shell.execute_reply.started": "2024-06-12T07:50:16.514002Z",
          "shell.execute_reply": "2024-06-12T07:50:32.441904Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos las m칠tricas\n",
        "\n",
        "from seqeval.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "def calculate_metrics(preds, y_true, pad_idx=PAD_TAG_IDX, o_idx=O_TAG_IDX):\n",
        "    \"\"\"\n",
        "    Calcula precision, recall y f1 de cada batch.\n",
        "    \"\"\"\n",
        "\n",
        "    # Obtener el indice de la clase con probabilidad mayor. (clases)\n",
        "    y_pred = preds.argmax(dim=1, keepdim=True)\n",
        "\n",
        "    # filtramos <pad> para calcular los scores.\n",
        "    mask = [(y_true != pad_idx)]\n",
        "    y_pred = y_pred[mask]\n",
        "    y_true = y_true[mask]\n",
        "\n",
        "    # traemos a la cpu\n",
        "    y_pred = y_pred.view(-1).to('cpu').numpy()\n",
        "    y_true = y_true.to('cpu').numpy()\n",
        "    y_pred = [[NER_TAGS.vocab.get_itos()[v] for v in y_pred]]\n",
        "    y_true = [[NER_TAGS.vocab.get_itos()[v] for v in y_true]]\n",
        "\n",
        "    # calcular scores\n",
        "    f1 = f1_score(y_true, y_pred, mode='strict')\n",
        "    precision = precision_score(y_true, y_pred, mode='strict')\n",
        "    recall = recall_score(y_true, y_pred, mode='strict')\n",
        "\n",
        "    return precision, recall, f1"
      ],
      "metadata": {
        "id": "YdWPWTMTy8Cm",
        "execution": {
          "iopub.status.busy": "2024-06-12T07:50:51.190015Z",
          "iopub.execute_input": "2024-06-12T07:50:51.190436Z",
          "iopub.status.idle": "2024-06-12T07:50:52.179855Z",
          "shell.execute_reply.started": "2024-06-12T07:50:51.1904Z",
          "shell.execute_reply": "2024-06-12T07:50:52.178718Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Modelo Baseline**\n",
        "\n",
        "Teniendo ya cargado los datos, toca definir nuestro modelo. Este baseline tendr치 una capa de embedding, unas cuantas LSTM y una capa de salida y usar치 dropout en el entrenamiento.\n",
        "\n",
        "Este constar치 de los siguientes pasos:\n",
        "\n",
        "1. Definir la clase que contendr치 la red.\n",
        "2. Definir los hiperpar치metros e inicializar la red.\n",
        "3. Definir el n칰mero de 칠pocas de entrenamiento\n",
        "4. Definir la funci칩n de loss.\n",
        "\n",
        "\n",
        "\n",
        "Recomendamos que para experimentar, encapsules los modelos en una sola variable y luego la fijes en model para entrenarla"
      ],
      "metadata": {
        "id": "eN984Z0XzHkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "# Definir la red\n",
        "class NER_RNN(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_dim,\n",
        "                 embedding_dim,\n",
        "                 hidden_dim,\n",
        "                 output_dim,\n",
        "                 n_layers,\n",
        "                 bidirectional,\n",
        "                 dropout,\n",
        "                 pad_idx):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # Capa de embedding\n",
        "        self.embedding = nn.Embedding(input_dim,\n",
        "                                      embedding_dim,\n",
        "                                      padding_idx=pad_idx,\n",
        "                                      )\n",
        "\n",
        "        # Capa LSTM\n",
        "        self.lstm = nn.LSTM(embedding_dim,\n",
        "                           hidden_dim,\n",
        "                           num_layers=n_layers,\n",
        "                           bidirectional=bidirectional,\n",
        "                           dropout = dropout if n_layers > 1 else 0)\n",
        "\n",
        "        # Capa de salida\n",
        "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim,\n",
        "                            output_dim)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text):\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "\n",
        "        # Convertir lo enviado a embedding\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "\n",
        "        outputs, (hidden, cell) = self.lstm(embedded)\n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "\n",
        "        # Pasar los embeddings por la rnn (LSTM)\n",
        "\n",
        "        #output = [sent len, batch size, hid dim * n directions]\n",
        "        #hidden/cell = [n layers * n directions, batch size, hid dim]\n",
        "\n",
        "        # Predecir usando la capa de salida.\n",
        "        predictions = self.fc(self.dropout(outputs))\n",
        "        #predictions = [sent len, batch size, output dim]\n",
        "\n",
        "        return predictions"
      ],
      "metadata": {
        "id": "G3vNCpAyy7_L",
        "execution": {
          "iopub.status.busy": "2024-06-12T07:50:55.322064Z",
          "iopub.execute_input": "2024-06-12T07:50:55.32246Z",
          "iopub.status.idle": "2024-06-12T07:50:55.332947Z",
          "shell.execute_reply.started": "2024-06-12T07:50:55.322426Z",
          "shell.execute_reply": "2024-06-12T07:50:55.332056Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hiperpar치metros de la red"
      ],
      "metadata": {
        "id": "3Ofso-aozeSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tama침o del vocabulario. recuerden que la entrada son vectores bag of word(one-hot).\n",
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 300  # dimensi칩n de los embeddings.\n",
        "HIDDEN_DIM = 256  # dimensi칩n de la capas LSTM\n",
        "OUTPUT_DIM = len(NER_TAGS.vocab)  # n칰mero de clases\n",
        "\n",
        "N_LAYERS = 1  # n칰mero de capas.\n",
        "DROPOUT = 0.0\n",
        "BIDIRECTIONAL = False\n",
        "\n",
        "# Creamos nuestro modelo.\n",
        "baseline_model = NER_RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM,\n",
        "                         N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX)\n",
        "\n",
        "baseline_model_name = 'baseline'  # nombre que tendr치 el modelo guardado...\n",
        "\n",
        "baseline_n_epochs = 10"
      ],
      "metadata": {
        "id": "9ryN9aKzy773",
        "execution": {
          "iopub.status.busy": "2024-06-12T07:50:58.841833Z",
          "iopub.execute_input": "2024-06-12T07:50:58.842697Z",
          "iopub.status.idle": "2024-06-12T07:50:58.90004Z",
          "shell.execute_reply.started": "2024-06-12T07:50:58.842662Z",
          "shell.execute_reply": "2024-06-12T07:50:58.899256Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos la funci칩n de loss"
      ],
      "metadata": {
        "id": "TfGxRLBwzhsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss: Cross Entropy\n",
        "TAG_PAD_IDX = NER_TAGS.vocab.get_stoi()['<PAD>']\n",
        "baseline_criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)"
      ],
      "metadata": {
        "id": "LtfG9RUQy7vx",
        "execution": {
          "iopub.status.busy": "2024-06-12T07:51:02.156379Z",
          "iopub.execute_input": "2024-06-12T07:51:02.156728Z",
          "iopub.status.idle": "2024-06-12T07:51:02.161496Z",
          "shell.execute_reply.started": "2024-06-12T07:51:02.156703Z",
          "shell.execute_reply": "2024-06-12T07:51:02.1605Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Entrenamos y evaluamos**\n",
        "\n",
        "\n",
        "**Importante** : Fijen el modelo, el n칰mero de 칠pocas de entrenamiento, la loss y el optimizador que usar치n para entrenar y evaluar en las siguientes variables!!!"
      ],
      "metadata": {
        "id": "Dg2Lm8Yszu11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = baseline_model\n",
        "model_name = baseline_model_name\n",
        "criterion = baseline_criterion\n",
        "n_epochs = baseline_n_epochs"
      ],
      "metadata": {
        "id": "1-TnXy2LzvXO",
        "execution": {
          "iopub.status.busy": "2024-06-12T07:51:04.366767Z",
          "iopub.execute_input": "2024-06-12T07:51:04.367512Z",
          "iopub.status.idle": "2024-06-12T07:51:04.371822Z",
          "shell.execute_reply.started": "2024-06-12T07:51:04.36748Z",
          "shell.execute_reply": "2024-06-12T07:51:04.370821Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Inicializamos la red**\n",
        "\n",
        "Iniciamos los pesos de la red de forma aleatoria (Usando una distribuci칩n normal)."
      ],
      "metadata": {
        "id": "x3wQq18i0Ehc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights(m):\n",
        "    # Inicializamos los pesos como aleatorios\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.normal_(param.data, mean=0, std=0.1)\n",
        "\n",
        "    # Seteamos como 0 los embeddings de UNK y PAD.\n",
        "    model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "    model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "model.apply(init_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kgtnu2L0E-B",
        "outputId": "6f377ac1-3a74-493b-d609-ebe5ca8d0f4b",
        "execution": {
          "iopub.status.busy": "2024-06-12T07:51:06.528789Z",
          "iopub.execute_input": "2024-06-12T07:51:06.529417Z",
          "iopub.status.idle": "2024-06-12T07:51:06.615016Z",
          "shell.execute_reply.started": "2024-06-12T07:51:06.529384Z",
          "shell.execute_reply": "2024-06-12T07:51:06.61412Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 16,
          "output_type": "execute_result",
          "data": {
            "text/plain": "NER_RNN(\n  (embedding): Embedding(16496, 300, padding_idx=0)\n  (lstm): LSTM(300, 256)\n  (fc): Linear(in_features=256, out_features=12, bias=True)\n  (dropout): Dropout(p=0.0, inplace=False)\n)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'El modelo actual tiene {count_parameters(model):,} par치metros entrenables.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2TB3-J80aBB",
        "outputId": "11d1c534-c709-49b6-9d6d-91056d68b617",
        "execution": {
          "iopub.status.busy": "2024-06-12T07:51:09.666116Z",
          "iopub.execute_input": "2024-06-12T07:51:09.666484Z",
          "iopub.status.idle": "2024-06-12T07:51:09.672096Z",
          "shell.execute_reply.started": "2024-06-12T07:51:09.666455Z",
          "shell.execute_reply": "2024-06-12T07:51:09.671086Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "El modelo actual tiene 5,523,276 par치metros entrenables.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notar que definimos los embeddings que representan a \\<unk\\> y \\<pad\\>  como [0, 0, ..., 0]"
      ],
      "metadata": {
        "id": "Gnuk_Hs10djW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos el optimizador"
      ],
      "metadata": {
        "id": "7qJhs1OX0gls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizador\n",
        "optimizer = optim.Adam(model.parameters()) # SGD, AdamW"
      ],
      "metadata": {
        "id": "xBAYockO0mE7",
        "execution": {
          "iopub.status.busy": "2024-06-12T07:51:12.358524Z",
          "iopub.execute_input": "2024-06-12T07:51:12.358891Z",
          "iopub.status.idle": "2024-06-12T07:51:13.837881Z",
          "shell.execute_reply.started": "2024-06-12T07:51:12.358862Z",
          "shell.execute_reply": "2024-06-12T07:51:13.83692Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enviamos el modelo a cuda"
      ],
      "metadata": {
        "id": "RGj6tfdd0qJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enviamos el modelo y la loss a cuda (en el caso en que est칠 disponible)\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "id": "_68iNmcN0qkm",
        "execution": {
          "iopub.status.busy": "2024-06-12T07:51:16.322123Z",
          "iopub.execute_input": "2024-06-12T07:51:16.323058Z",
          "iopub.status.idle": "2024-06-12T07:51:16.376172Z",
          "shell.execute_reply.started": "2024-06-12T07:51:16.323024Z",
          "shell.execute_reply": "2024-06-12T07:51:16.375283Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Definimos el entrenamiento de la red**\n",
        "\n",
        "Algunos conceptos previos:\n",
        "\n",
        "- `epoch` : una pasada de entrenamiento completa de una dataset.\n",
        "- `batch`: una fracci칩n de la 칠poca. Se utilizan para entrenar mas r치pidamente la red. (mas eficiente pasar n datos que uno en cada ejecuci칩n del backpropagation)\n",
        "\n",
        "Esta funci칩n est치 encargada de entrenar la red en una 칠poca. Para esto, por cada batch de la 칠poca actual, predice los tags del texto, calcula su loss y luego hace backpropagation para actualizar los pesos de la red.\n",
        "\n",
        "Observaci칩n: En algunos comentarios aparecer치 el tama침o de los tensores entre corchetes"
      ],
      "metadata": {
        "id": "BuKvsbrw0wHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_precision = 0\n",
        "    epoch_recall = 0\n",
        "    epoch_f1 = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # Por cada batch del iterador de la 칠poca:\n",
        "    for tags, text in iterator:\n",
        "        # Reiniciamos los gradientes calculados en la iteraci칩n anterior\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "\n",
        "        # Predecimos los tags del texto del batch.\n",
        "        predictions = model(text.to(device))\n",
        "\n",
        "        #predictions = [sent len, batch size, output dim]\n",
        "        #tags = [sent len, batch size]\n",
        "\n",
        "        # Reordenamos los datos para calcular la loss\n",
        "        predictions = predictions.view(-1, predictions.shape[-1])\n",
        "        #ipdb.set_trace()\n",
        "        tags = torch.reshape(tags, (-1,)).to(device)\n",
        "\n",
        "        #predictions = [sent len * batch size, output dim]\n",
        "\n",
        "        # Calculamos el Cross Entropy de las predicciones con respecto a las etiquetas reales\n",
        "        loss = criterion(predictions, tags)\n",
        "\n",
        "        # Calculamos el accuracy\n",
        "        precision, recall, f1 = calculate_metrics(predictions, tags)\n",
        "\n",
        "        # Calculamos los gradientes\n",
        "        loss.backward()\n",
        "\n",
        "        # Actualizamos los par치metros de la red\n",
        "        optimizer.step()\n",
        "\n",
        "        # Actualizamos el loss y las m칠tricas\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_precision += precision\n",
        "        epoch_recall += recall\n",
        "        epoch_f1 += f1\n",
        "\n",
        "    return ( epoch_loss / len(iterator), epoch_precision / len(iterator),\n",
        "              epoch_recall / len(iterator), epoch_f1 / len(iterator) )"
      ],
      "metadata": {
        "id": "ShIJbx2v0wlf",
        "execution": {
          "iopub.status.busy": "2024-06-12T07:51:19.263398Z",
          "iopub.execute_input": "2024-06-12T07:51:19.263754Z",
          "iopub.status.idle": "2024-06-12T07:51:19.272479Z",
          "shell.execute_reply.started": "2024-06-12T07:51:19.263726Z",
          "shell.execute_reply": "2024-06-12T07:51:19.271472Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Definimos la funci칩n de evaluaci칩n**\n",
        "\n",
        "Evalua el rendimiento actual de la red usando los datos de validaci칩n.\n",
        "\n",
        "Por cada batch de estos datos, calcula y reporta el loss y las m칠tricas asociadas al conjunto de validaci칩n.\n",
        "Ya que las m칠tricas son calculadas por cada batch, estas son retornadas promediadas por el n칰mero de batches entregados. (ver linea del return)"
      ],
      "metadata": {
        "id": "IWSosAit0xCJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_precision = 0\n",
        "    epoch_recall = 0\n",
        "    epoch_f1 = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Indicamos que ahora no guardaremos los gradientes\n",
        "    with torch.no_grad():\n",
        "        # Por cada batch\n",
        "        for tags, text in iterator:\n",
        "            # Predecimos\n",
        "            predictions = model(text.to(device))\n",
        "\n",
        "            predictions = predictions.view(-1, predictions.shape[-1])\n",
        "            tags = torch.reshape(tags, (-1,)).to(device)\n",
        "\n",
        "            # Calculamos el Cross Entropy de las predicciones con respecto a las etiquetas reales\n",
        "            loss = criterion(predictions, tags)\n",
        "\n",
        "            # Calculamos las m칠tricas\n",
        "            precision, recall, f1 = calculate_metrics(predictions, tags)\n",
        "\n",
        "            # Actualizamos el loss y las m칠tricas\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_precision += precision\n",
        "            epoch_recall += recall\n",
        "            epoch_f1 += f1\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_precision / len(\n",
        "        iterator), epoch_recall / len(iterator), epoch_f1 / len(iterator)"
      ],
      "metadata": {
        "id": "Z3fRycaX0xbA",
        "execution": {
          "iopub.status.busy": "2024-06-12T07:51:22.161669Z",
          "iopub.execute_input": "2024-06-12T07:51:22.162019Z",
          "iopub.status.idle": "2024-06-12T07:51:22.169722Z",
          "shell.execute_reply.started": "2024-06-12T07:51:22.161988Z",
          "shell.execute_reply": "2024-06-12T07:51:22.168809Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "tA8nad2A1HUm",
        "execution": {
          "iopub.status.busy": "2024-06-12T07:51:25.889363Z",
          "iopub.execute_input": "2024-06-12T07:51:25.890109Z",
          "iopub.status.idle": "2024-06-12T07:51:25.895708Z",
          "shell.execute_reply.started": "2024-06-12T07:51:25.890077Z",
          "shell.execute_reply": "2024-06-12T07:51:25.894622Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Entrenamiento de la red**\n",
        "\n",
        "En este cuadro de c칩digo ejecutaremos el entrenamiento de la red.\n",
        "Para esto, primero definiremos el n칰mero de 칠pocas y luego por cada 칠poca, ejecutaremos `train` y `evaluate`.\n",
        "\n",
        "**Importante: Reiniciar los pesos del modelo**\n",
        "\n",
        "Si ejecutas nuevamente esta celda, se seguira entrenando el mismo modelo una y otra vez.\n",
        "Para reiniciar el modelo se debe ejecutar nuevamente la celda que contiene la funci칩n `init_weights`."
      ],
      "metadata": {
        "id": "2twwfpmz1E7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Recuerdo: dataloader_train y valid_iterator contienen el dataset dividido en batches\n",
        "\n",
        "    # Entrenar\n",
        "    train_loss, train_precision, train_recall, train_f1 = train(\n",
        "        model, dataloader_train, optimizer, criterion)\n",
        "\n",
        "    # Evaluar (valid = validaci칩n)\n",
        "    valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(\n",
        "        model, dataloader_dev, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    # Si obtuvimos mejores resultados, guardamos este modelo en el almacenamiento (para poder cargarlo luego)\n",
        "    # Si detienen el entrenamiento prematuramente, pueden cargar el modelo en el siguiente recuadro de c칩digo\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), '{}.pt'.format(model_name))\n",
        "    # Si ya no mejoramos el loss de validaci칩n, terminamos de entrenar\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(\n",
        "        f'\\tTrain Loss: {train_loss:.3f} | Train f1: {train_f1:.2f} | Train precision: {train_precision:.2f} | Train recall: {train_recall:.2f}'\n",
        "    )\n",
        "    print(\n",
        "        f'\\t Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} |  Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}'\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0Py5sCE1FTe",
        "outputId": "447e1f92-55f4-482f-fad5-8e77b9d3c9e1",
        "execution": {
          "iopub.status.busy": "2024-06-12T06:39:56.56689Z",
          "iopub.execute_input": "2024-06-12T06:39:56.567544Z",
          "iopub.status.idle": "2024-06-12T06:41:00.756415Z",
          "shell.execute_reply.started": "2024-06-12T06:39:56.567506Z",
          "shell.execute_reply": "2024-06-12T06:41:00.755294Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: <PAD> seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch: 01 | Epoch Time: 0m 7s\n\tTrain Loss: 0.716 | Train f1: 0.48 | Train precision: 0.61 | Train recall: 0.41\n\t Val. Loss: 0.435 |  Val. f1: 0.70 |  Val. precision: 0.75 | Val. recall: 0.66\nEpoch: 02 | Epoch Time: 0m 6s\n\tTrain Loss: 0.314 | Train f1: 0.77 | Train precision: 0.80 | Train recall: 0.74\n\t Val. Loss: 0.373 |  Val. f1: 0.73 |  Val. precision: 0.76 | Val. recall: 0.71\nEpoch: 03 | Epoch Time: 0m 6s\n\tTrain Loss: 0.193 | Train f1: 0.86 | Train precision: 0.87 | Train recall: 0.85\n\t Val. Loss: 0.392 |  Val. f1: 0.74 |  Val. precision: 0.78 | Val. recall: 0.70\nEpoch: 04 | Epoch Time: 0m 6s\n\tTrain Loss: 0.136 | Train f1: 0.90 | Train precision: 0.90 | Train recall: 0.90\n\t Val. Loss: 0.427 |  Val. f1: 0.74 |  Val. precision: 0.78 | Val. recall: 0.70\nEpoch: 05 | Epoch Time: 0m 6s\n\tTrain Loss: 0.102 | Train f1: 0.93 | Train precision: 0.93 | Train recall: 0.93\n\t Val. Loss: 0.449 |  Val. f1: 0.74 |  Val. precision: 0.79 | Val. recall: 0.70\nEpoch: 06 | Epoch Time: 0m 6s\n\tTrain Loss: 0.079 | Train f1: 0.94 | Train precision: 0.94 | Train recall: 0.94\n\t Val. Loss: 0.465 |  Val. f1: 0.73 |  Val. precision: 0.73 | Val. recall: 0.73\nEpoch: 07 | Epoch Time: 0m 6s\n\tTrain Loss: 0.062 | Train f1: 0.95 | Train precision: 0.95 | Train recall: 0.96\n\t Val. Loss: 0.507 |  Val. f1: 0.72 |  Val. precision: 0.73 | Val. recall: 0.72\nEpoch: 08 | Epoch Time: 0m 6s\n\tTrain Loss: 0.050 | Train f1: 0.96 | Train precision: 0.96 | Train recall: 0.96\n\t Val. Loss: 0.532 |  Val. f1: 0.72 |  Val. precision: 0.71 | Val. recall: 0.72\nEpoch: 09 | Epoch Time: 0m 6s\n\tTrain Loss: 0.042 | Train f1: 0.97 | Train precision: 0.97 | Train recall: 0.97\n\t Val. Loss: 0.590 |  Val. f1: 0.71 |  Val. precision: 0.69 | Val. recall: 0.73\nEpoch: 10 | Epoch Time: 0m 6s\n\tTrain Loss: 0.035 | Train f1: 0.97 | Train precision: 0.97 | Train recall: 0.97\n\t Val. Loss: 0.628 |  Val. f1: 0.72 |  Val. precision: 0.72 | Val. recall: 0.72\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importante**: Recuerden que el 칰ltimo modelo entrenado no es el mejor (probablemente est칠 *overfitteado*), si no el que guardamos con la menor loss del conjunto de validaci칩n. Este problema lo pueden solucionar con *early stopping*.\n",
        "Para cargar el mejor modelo entrenado, ejecuten la siguiente celda."
      ],
      "metadata": {
        "id": "zMU8i9eV-xYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cargar el mejor modelo entrenado.\n",
        "model.load_state_dict(torch.load('{}.pt'.format(model_name)))"
      ],
      "metadata": {
        "id": "tqJU5AEY-bwK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6839be35-4edc-4a6c-e6c8-77ee6da94c2f",
        "execution": {
          "iopub.status.busy": "2024-06-12T06:41:44.832832Z",
          "iopub.execute_input": "2024-06-12T06:41:44.833575Z",
          "iopub.status.idle": "2024-06-12T06:41:44.854168Z",
          "shell.execute_reply.started": "2024-06-12T06:41:44.833534Z",
          "shell.execute_reply": "2024-06-12T06:41:44.853087Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 24,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<All keys matched successfully>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Limpiar ram de cuda\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "JX84ETMg-1Qv",
        "execution": {
          "iopub.status.busy": "2024-06-12T06:41:47.005675Z",
          "iopub.execute_input": "2024-06-12T06:41:47.006387Z",
          "iopub.status.idle": "2024-06-12T06:41:47.016097Z",
          "shell.execute_reply.started": "2024-06-12T06:41:47.006354Z",
          "shell.execute_reply": "2024-06-12T06:41:47.015112Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Evaluamos el set de validaci칩n con el modelo final**\n",
        "\n",
        "Estos son los resultados de predecir el dataset de evaluaci칩n con el *mejor* modelo entrenado."
      ],
      "metadata": {
        "id": "_d9Yfz95_GIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(\n",
        "    model, dataloader_dev, criterion)\n",
        "\n",
        "print(\n",
        "    f'Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} | Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}'\n",
        ")"
      ],
      "metadata": {
        "id": "Y6mMnQIC-2G2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f52a626-8ab6-4640-bd9a-16940ebd072f",
        "execution": {
          "iopub.status.busy": "2024-06-12T06:41:51.867429Z",
          "iopub.execute_input": "2024-06-12T06:41:51.867834Z",
          "iopub.status.idle": "2024-06-12T06:41:52.380998Z",
          "shell.execute_reply.started": "2024-06-12T06:41:51.867801Z",
          "shell.execute_reply": "2024-06-12T06:41:52.380095Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Val. Loss: 0.373 |  Val. f1: 0.73 | Val. precision: 0.76 | Val. recall: 0.71\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Evaluamos el set de prueba con el modelo final**\n",
        "\n",
        "Estos son los resultados de predecir el dataset de prueba con el *mejor* modelo entrenado."
      ],
      "metadata": {
        "id": "K7FzQVxK-2kc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prueba_loss, prueba_precision, prueba_recall, prueba_f1 = evaluate(\n",
        "    model, dataloader_test, criterion)\n",
        "\n",
        "print(\n",
        "    f'Test. Loss: {prueba_loss:.3f} |  Test. f1: {prueba_f1:.2f} | Test. precision: {prueba_precision:.2f} | Test. recall: {prueba_recall:.2f}'\n",
        ")"
      ],
      "metadata": {
        "id": "meu3CsgT-3PE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6366d33e-49a4-40df-e2f4-0587a8195ee1",
        "execution": {
          "iopub.status.busy": "2024-06-12T06:41:56.743509Z",
          "iopub.execute_input": "2024-06-12T06:41:56.744164Z",
          "iopub.status.idle": "2024-06-12T06:41:57.274036Z",
          "shell.execute_reply.started": "2024-06-12T06:41:56.744129Z",
          "shell.execute_reply": "2024-06-12T06:41:57.2731Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Test. Loss: 0.393 |  Test. f1: 0.73 | Test. precision: 0.76 | Test. recall: 0.71\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experimentos\n",
        "\n",
        "En esta secci칩n deberan explicar, implementar y evaluar **TRES EXPERIMENTO DIFERENTES**. Puede revisar la [lista de sugerencias](#scrollTo=TfMlGTCgIq8o) al inicio del enunciado para sacar ideas de experimentos. Se espera que los experimentos sean relevantes y desafiantes.\n",
        "\n",
        "Cada experimento debe contener las siguientes cuatro subsecciones:\n",
        "\n",
        "- *Explicaci칩n del experimento*: debe motivar y explicar en que consiste su experimento. La explicaci칩n debe fundamentar porque es un experimento relevante y desafiantes, ademas de aclarar que estudiaran.\n",
        "\n",
        "- *Implementacion del experimento*: debe implementar su experimento con codigo debidamente comentado, con tal de que sea legible.\n",
        "\n",
        "- *Evaluar el experimento*: debe evaluar con las metricas propuestas para generar los resultados obtenidos con sus experimentos sobre el conjunto de prueba.\n",
        "\n",
        "- *Analizar el experimento*: debe hacer un breve analisis de los resultados obtenidos."
      ],
      "metadata": {
        "id": "F2bRYNRnKRzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar librerias\n",
        "import numpy as np\n",
        "from gensim.models import KeyedVectors"
      ],
      "metadata": {
        "id": "TfzWYHZCI9bN",
        "execution": {
          "iopub.status.busy": "2024-06-12T07:54:41.774843Z",
          "iopub.execute_input": "2024-06-12T07:54:41.775211Z",
          "iopub.status.idle": "2024-06-12T07:54:54.980496Z",
          "shell.execute_reply.started": "2024-06-12T07:54:41.775182Z",
          "shell.execute_reply": "2024-06-12T07:54:54.979587Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Experimento 1**"
      ],
      "metadata": {
        "id": "QwdOcPfbL3pH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Explicaci칩n"
      ],
      "metadata": {
        "id": "Gkn38sTsdpzR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cambios con respecto al modelo baseline:\n",
        "\n",
        "- Aplicaci칩n de la capa de embeddings preentrenados de \"Chilean Waiting List\".\n",
        "- Reemplazo de la capa LSTM por una capa GRU.\n",
        "- Inclusi칩n de una capa de dropout con una tasa de 0.6.\n",
        "- Configuraci칩n de la capa GRU como bidireccional.\n",
        "\n",
        "En este experimento, se integraron embeddings pre-entrenados de \"Chilean Waiting List\", lo que no solo enriquece la calidad de las representaciones de las palabras, sino que tambi칠n acelera el proceso de entrenamiento al proporcionar un punto de partida s칩lido. Luego, se reemplaz칩 la capa LSTM por una capa GRU, que es menos compleja computacionalmente y puede manejar mejor la desaparici칩n del gradiente. Adem치s, se a침adi칩 una capa de dropout con una tasa de 0.6 para prevenir el sobreajuste, mejorando as칤 la generalizaci칩n del modelo. Finalmente, la configuraci칩n bidireccional de la capa GRU permite capturar dependencias contextuales tanto del pasado como del futuro en la secuencia de texto, enriqueciendo la capacidad del modelo para reconocer entidades nombradas con mayor precisi칩n.\n",
        "\n",
        "Este experimento es relevante para evaluar el tradeoff entre el rendimiento de un modelo GRU bidireccional y un modelo LSTM unidireccional, manteniendo una cantidad de par치metros similar."
      ],
      "metadata": {
        "id": "r9Cr3jl1d0F3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Implementaci칩n"
      ],
      "metadata": {
        "id": "Q5dlEgEqdtvp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NER_RNN_EMB_GRU(nn.Module):\n",
        "      \"\"\"\n",
        "      Modelo de red neuronal para tarea de Name Entity Recognition (NER)\n",
        "      utilizando capas GRU con embeddings pre-entrenados.\n",
        "\n",
        "      Parameters\n",
        "      ----------\n",
        "      embedding_dim : int\n",
        "              Dimensi칩n de los embeddings.\n",
        "      hidden_dim : int\n",
        "              Dimensi칩n de las capas ocultas de GRU.\n",
        "      output_dim : int\n",
        "              Dimensi칩n de la salida (n칰mero de etiquetas de NER).\n",
        "      n_layers : int\n",
        "              N칰mero de capas de GRU.\n",
        "      bidirectional : bool\n",
        "              Si la GRU es bidireccional.\n",
        "      dropout : float\n",
        "              Tasa de dropout.\n",
        "      pad_idx : int\n",
        "              칈ndice de padding en el vocabulario.\n",
        "      pretrained_embeddings : Tensor\n",
        "              Embeddings pre-entrenados a utilizar.\n",
        "      \"\"\"\n",
        "      def __init__(self,\n",
        "                  embedding_dim,\n",
        "                  hidden_dim,\n",
        "                  output_dim,\n",
        "                  n_layers,\n",
        "                  bidirectional,\n",
        "                  dropout,\n",
        "                  pad_idx,\n",
        "                  pretrained_embeddings\n",
        "                  ):\n",
        "\n",
        "          super(NER_RNN_EMB_GRU, self).__init__()\n",
        "\n",
        "          # Capa de embeddings utilizando embeddings pre-entrenados\n",
        "          self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings,\n",
        "                                                        freeze=False,\n",
        "                                                        padding_idx=pad_idx\n",
        "                                                        )\n",
        "          # Dimensi칩n de los embeddings\n",
        "          self.embedding_dim = embedding_dim\n",
        "\n",
        "          # Capa GRU\n",
        "          self.gru = nn.GRU(self.embedding_dim,\n",
        "                            hidden_dim,\n",
        "                            num_layers=n_layers,\n",
        "                            bidirectional=bidirectional,\n",
        "                            dropout=dropout if n_layers > 1 else 0\n",
        "                            )\n",
        "\n",
        "          # Capa de salida\n",
        "          self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim,\n",
        "                              output_dim\n",
        "                              )\n",
        "\n",
        "          # Capa de Dropout\n",
        "          self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "      def forward(self, text):\n",
        "          \"\"\"\n",
        "          Define el paso hacia adelante de la red.\n",
        "\n",
        "          Parameters\n",
        "          ----------\n",
        "          text : Tensor\n",
        "              Tensor de entrada de tama침o [sent len, batch size].\n",
        "\n",
        "          Returns\n",
        "          -------\n",
        "          Tensor :\n",
        "              Predicciones de la red de tama침o [sent len, batch size, output dim].\n",
        "          \"\"\"\n",
        "          # Aplicar embeddings y dropout\n",
        "          embedded = self.dropout(self.embedding(text)) # embedded = [sent len, batch size, emb dim]\n",
        "\n",
        "          # Pasar los embeddings por la GRU\n",
        "          outputs, h_n = self.gru(embedded) # outputs = [sent len, batch size, hid dim * n directions]\n",
        "\n",
        "          # Pasar las salidas por la capa de dropout y la capa lineal\n",
        "          predictions = self.fc(self.dropout(outputs)) # predictions = [sent len, batch size, output dim]\n",
        "\n",
        "          return predictions"
      ],
      "metadata": {
        "id": "9YaXlYy9GFBP",
        "execution": {
          "iopub.status.busy": "2024-06-12T06:43:25.163357Z",
          "iopub.execute_input": "2024-06-12T06:43:25.16394Z",
          "iopub.status.idle": "2024-06-12T06:43:25.174374Z",
          "shell.execute_reply.started": "2024-06-12T06:43:25.163908Z",
          "shell.execute_reply": "2024-06-12T06:43:25.173443Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hcb_54JcHsaB",
        "outputId": "57f8661d-2ad2-44e9-b7bc-d3fb1a37920b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Mounted at /content/drive\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ruta al archivo de embeddings pre-entrenados\n",
        "pretrained_embedding_path = '/content/drive/MyDrive/cwlce.vec'\n",
        "\n",
        "# Cargar embeddings pre-entrenados en formato word2vec\n",
        "word_vectors = KeyedVectors.load_word2vec_format(pretrained_embedding_path, binary=False)\n",
        "\n",
        "# Obtener vocabulario\n",
        "vocab = TEXT.vocab\n",
        "\n",
        "count=[]\n",
        "# Asignar embeddings pre-entrenados a los tokens del vocabulario\n",
        "for token, idx in vocab.get_stoi().items():\n",
        "    # Verificar si el token est치 en los embeddings pre-entrenados\n",
        "    if token.lower() in word_vectors.key_to_index:\n",
        "        count.append(idx)\n",
        "print(f\"Cantidad de tokens coincidentes: {len(count)}\")"
      ],
      "metadata": {
        "id": "N3DmdBWE5JxT",
        "execution": {
          "iopub.status.busy": "2024-06-12T06:46:32.30977Z",
          "iopub.execute_input": "2024-06-12T06:46:32.31067Z",
          "iopub.status.idle": "2024-06-12T06:46:47.998355Z",
          "shell.execute_reply.started": "2024-06-12T06:46:32.310634Z",
          "shell.execute_reply": "2024-06-12T06:46:47.997461Z"
        },
        "trusted": true,
        "outputId": "e14f7d2a-4355-4b33-c673-2852ed0ce003"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Cantidad de tokens coincidentes: 12947\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dimensi칩n de los embeddings pre-entrenados\n",
        "embedding_dim = word_vectors.vector_size\n",
        "\n",
        "# Inicializar la matriz de embeddings con ceros\n",
        "embedding_matrix = torch.zeros(len(TEXT), embedding_dim)\n",
        "\n",
        "# Asignar embeddings pre-entrenados a los tokens del vocabulario\n",
        "for token, idx in TEXT.get_stoi().items():\n",
        "    # Verificar si el token est치 en los embeddings pre-entrenados\n",
        "    if token.lower() in word_vectors.key_to_index:\n",
        "        embedding_matrix[idx] = torch.tensor(np.copy(word_vectors[token.lower()]), dtype=torch.float)\n",
        "    elif token == '<PAD>':\n",
        "        # Si el token es '<PAD>', asignar un vector de ceros\n",
        "        embedding_matrix[idx] = torch.zeros(embedding_dim)\n",
        "    else:\n",
        "        # Si el token no est치 en los embeddings pre-entrenados, asignar un vector aleatorio\n",
        "        embedding_matrix[idx] = torch.randn(embedding_dim)"
      ],
      "metadata": {
        "id": "VRrpbfrkykMW",
        "execution": {
          "iopub.status.busy": "2024-06-12T06:46:55.975692Z",
          "iopub.execute_input": "2024-06-12T06:46:55.97668Z",
          "iopub.status.idle": "2024-06-12T06:46:56.335708Z",
          "shell.execute_reply.started": "2024-06-12T06:46:55.976642Z",
          "shell.execute_reply": "2024-06-12T06:46:56.334653Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# INPUT_DIM = len(TEXT.vocab)\n",
        "PRETRAINED_EMBEDDINGS = embedding_matrix # Utilizamos la matriz de embeddings preentrenados creada anteriormente\n",
        "EMBEDDING_DIM = embedding_dim # Dimensi칩n de los embeddings\n",
        "HIDDEN_DIM = 256 # Dimensi칩n de las capas GRU\n",
        "OUTPUT_DIM = len(NER_TAGS.vocab) # N칰mero de clases\n",
        "\n",
        "N_LAYERS = 1  # N칰mero de capas GRU\n",
        "DROPOUT = 0.6 # Tasa de Dropout\n",
        "BIDIRECTIONAL = True # Indicador de si la GRU es bidireccional\n",
        "\n",
        "# Crear una instancia del modelo NER_RNN_EMB_GRU\n",
        "model_1 = NER_RNN_EMB_GRU(embedding_dim=EMBEDDING_DIM,\n",
        "                          hidden_dim=HIDDEN_DIM,\n",
        "                          output_dim=OUTPUT_DIM,\n",
        "                          n_layers=N_LAYERS,\n",
        "                          bidirectional=BIDIRECTIONAL,\n",
        "                          dropout=DROPOUT,\n",
        "                          pad_idx=PAD_IDX,\n",
        "                          pretrained_embeddings=PRETRAINED_EMBEDDINGS).to(device)\n",
        "\n",
        "# Nombre que tendr치 el modelo guardado\n",
        "model_1_name = 'experimento_1'\n",
        "# N칰mero de 칠pocas para entrenar el modelo\n",
        "model_1_n_epochs = 10"
      ],
      "metadata": {
        "id": "dhuuMKVAdvqt",
        "execution": {
          "iopub.status.busy": "2024-06-12T06:47:02.172429Z",
          "iopub.execute_input": "2024-06-12T06:47:02.173063Z",
          "iopub.status.idle": "2024-06-12T06:47:02.196736Z",
          "shell.execute_reply.started": "2024-06-12T06:47:02.173028Z",
          "shell.execute_reply": "2024-06-12T06:47:02.195893Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss: Cross Entropy\n",
        "TAG_PAD_IDX = NER_TAGS.vocab.get_stoi()['<PAD>'] # Definir el 칤ndice de padding para las etiquetas\n",
        "model_1_criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX) # Definir la funci칩n de p칠rdida ignorando el 칤ndice de padding"
      ],
      "metadata": {
        "id": "tGs2HTvXLELL",
        "execution": {
          "iopub.status.busy": "2024-06-12T06:47:07.981194Z",
          "iopub.execute_input": "2024-06-12T06:47:07.981538Z",
          "iopub.status.idle": "2024-06-12T06:47:07.986285Z",
          "shell.execute_reply.started": "2024-06-12T06:47:07.981508Z",
          "shell.execute_reply": "2024-06-12T06:47:07.985395Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Asignar el modelo, el nombre del modelo, la funci칩n de p칠rdida y el n칰mero de 칠pocas de entrenamiento\n",
        "model = model_1\n",
        "model_name = model_1_name\n",
        "model_criterion = model_1_criterion\n",
        "model_n_epochs = model_1_n_epochs\n",
        "\n",
        "# Imprimir el n칰mero de par치metros entrenables en el modelo actual\n",
        "print(f'El modelo actual tiene {count_parameters(model):,} par치metros entrenables.')"
      ],
      "metadata": {
        "id": "NO6KeMGnK5zp",
        "execution": {
          "iopub.status.busy": "2024-06-12T06:47:12.513221Z",
          "iopub.execute_input": "2024-06-12T06:47:12.513582Z",
          "iopub.status.idle": "2024-06-12T06:47:12.519276Z",
          "shell.execute_reply.started": "2024-06-12T06:47:12.513545Z",
          "shell.execute_reply": "2024-06-12T06:47:12.518338Z"
        },
        "trusted": true,
        "outputId": "4b9bae6b-b770-4158-e967-8efa3f443170"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "El modelo actual tiene 5,812,044 par치metros entrenables.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicar la inicializaci칩n de pesos al modelo\n",
        "model.apply(init_weights)"
      ],
      "metadata": {
        "id": "sOzzYamIKvDw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "704f1e15-2b06-4f48-9abb-1c831d2f216f",
        "execution": {
          "iopub.status.busy": "2024-06-12T06:47:20.398981Z",
          "iopub.execute_input": "2024-06-12T06:47:20.399345Z",
          "iopub.status.idle": "2024-06-12T06:47:20.407488Z",
          "shell.execute_reply.started": "2024-06-12T06:47:20.399309Z",
          "shell.execute_reply": "2024-06-12T06:47:20.406635Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 37,
          "output_type": "execute_result",
          "data": {
            "text/plain": "NER_RNN_EMB_GRU(\n  (embedding): Embedding(16496, 300, padding_idx=0)\n  (gru): GRU(300, 256, bidirectional=True)\n  (fc): Linear(in_features=512, out_features=12, bias=True)\n  (dropout): Dropout(p=0.6, inplace=False)\n)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizador\n",
        "model_optimizer = optim.Adam(model.parameters()) # SGD, AdamW"
      ],
      "metadata": {
        "id": "59tpLCa2gtvQ",
        "execution": {
          "iopub.status.busy": "2024-06-12T06:48:23.294517Z",
          "iopub.execute_input": "2024-06-12T06:48:23.295235Z",
          "iopub.status.idle": "2024-06-12T06:48:23.299559Z",
          "shell.execute_reply.started": "2024-06-12T06:48:23.295201Z",
          "shell.execute_reply": "2024-06-12T06:48:23.298687Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enviar el modelo y la funci칩n de p칠rdida a la GPU (si est치 disponible)\n",
        "model = model.to(device)\n",
        "model_criterion = model_criterion.to(device)"
      ],
      "metadata": {
        "id": "4C1JHPxFfqAq",
        "execution": {
          "iopub.status.busy": "2024-06-12T06:48:43.243126Z",
          "iopub.execute_input": "2024-06-12T06:48:43.244114Z",
          "iopub.status.idle": "2024-06-12T06:48:43.249502Z",
          "shell.execute_reply.started": "2024-06-12T06:48:43.244075Z",
          "shell.execute_reply": "2024-06-12T06:48:43.248671Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_valid_loss = float('inf') # Inicializar la mejor p칠rdida de validaci칩n como infinita\n",
        "\n",
        "# Bucle de entrenamiento y validaci칩n para cada 칠poca\n",
        "for epoch in range(model_n_epochs):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Entrenar el modelo con el conjunto de entrenamiento\n",
        "    train_loss, train_precision, train_recall, train_f1 = train(\n",
        "        model, dataloader_train, model_optimizer, model_criterion)\n",
        "\n",
        "    # Evaluar el modelo en el conjunto de validaci칩n\n",
        "    valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(\n",
        "        model, dataloader_dev, model_criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "    # Calcular el tiempo de la 칠poca (minutos y segundos)\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    # Guardar el modelo si la p칠rdida de validaci칩n es la mejor obtenida hasta ahora\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), '{}.pt'.format(model_name))\n",
        "\n",
        "    # Imprimir resultados de la 칠poca\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(\n",
        "        f'\\tTrain Loss: {train_loss:.3f} | Train f1: {train_f1:.2f} | Train precision: {train_precision:.2f} | Train recall: {train_recall:.2f}'\n",
        "    )\n",
        "    print(\n",
        "        f'\\t Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} |  Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}'\n",
        "    )"
      ],
      "metadata": {
        "id": "2QkzOfIvKgmf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66a92415-00fa-4f02-cc29-caf769e2598d",
        "execution": {
          "iopub.status.busy": "2024-06-12T06:48:48.982638Z",
          "iopub.execute_input": "2024-06-12T06:48:48.983009Z",
          "iopub.status.idle": "2024-06-12T06:49:53.98523Z",
          "shell.execute_reply.started": "2024-06-12T06:48:48.982979Z",
          "shell.execute_reply": "2024-06-12T06:49:53.984199Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: <PAD> seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch: 01 | Epoch Time: 0m 6s\n\tTrain Loss: 0.810 | Train f1: 0.42 | Train precision: 0.57 | Train recall: 0.34\n\t Val. Loss: 0.469 |  Val. f1: 0.66 |  Val. precision: 0.80 | Val. recall: 0.57\nEpoch: 02 | Epoch Time: 0m 6s\n\tTrain Loss: 0.467 | Train f1: 0.66 | Train precision: 0.74 | Train recall: 0.61\n\t Val. Loss: 0.362 |  Val. f1: 0.73 |  Val. precision: 0.81 | Val. recall: 0.68\nEpoch: 03 | Epoch Time: 0m 6s\n\tTrain Loss: 0.333 | Train f1: 0.76 | Train precision: 0.80 | Train recall: 0.72\n\t Val. Loss: 0.342 |  Val. f1: 0.76 |  Val. precision: 0.80 | Val. recall: 0.72\nEpoch: 04 | Epoch Time: 0m 6s\n\tTrain Loss: 0.256 | Train f1: 0.81 | Train precision: 0.84 | Train recall: 0.79\n\t Val. Loss: 0.340 |  Val. f1: 0.77 |  Val. precision: 0.82 | Val. recall: 0.73\nEpoch: 05 | Epoch Time: 0m 6s\n\tTrain Loss: 0.201 | Train f1: 0.85 | Train precision: 0.87 | Train recall: 0.84\n\t Val. Loss: 0.350 |  Val. f1: 0.78 |  Val. precision: 0.82 | Val. recall: 0.75\nEpoch: 06 | Epoch Time: 0m 6s\n\tTrain Loss: 0.162 | Train f1: 0.88 | Train precision: 0.89 | Train recall: 0.87\n\t Val. Loss: 0.378 |  Val. f1: 0.78 |  Val. precision: 0.83 | Val. recall: 0.74\nEpoch: 07 | Epoch Time: 0m 6s\n\tTrain Loss: 0.135 | Train f1: 0.90 | Train precision: 0.91 | Train recall: 0.89\n\t Val. Loss: 0.390 |  Val. f1: 0.78 |  Val. precision: 0.83 | Val. recall: 0.74\nEpoch: 08 | Epoch Time: 0m 6s\n\tTrain Loss: 0.113 | Train f1: 0.92 | Train precision: 0.92 | Train recall: 0.91\n\t Val. Loss: 0.404 |  Val. f1: 0.78 |  Val. precision: 0.82 | Val. recall: 0.75\nEpoch: 09 | Epoch Time: 0m 6s\n\tTrain Loss: 0.096 | Train f1: 0.93 | Train precision: 0.93 | Train recall: 0.92\n\t Val. Loss: 0.416 |  Val. f1: 0.79 |  Val. precision: 0.80 | Val. recall: 0.78\nEpoch: 10 | Epoch Time: 0m 6s\n\tTrain Loss: 0.088 | Train f1: 0.93 | Train precision: 0.94 | Train recall: 0.93\n\t Val. Loss: 0.434 |  Val. f1: 0.79 |  Val. precision: 0.82 | Val. recall: 0.76\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el mejor modelo entrenado\n",
        "model.load_state_dict(torch.load('{}.pt'.format(model_name)))"
      ],
      "metadata": {
        "id": "OwsGHON7bSjE",
        "execution": {
          "iopub.status.busy": "2024-06-12T06:50:00.312458Z",
          "iopub.execute_input": "2024-06-12T06:50:00.312828Z",
          "iopub.status.idle": "2024-06-12T06:50:00.333211Z",
          "shell.execute_reply.started": "2024-06-12T06:50:00.312798Z",
          "shell.execute_reply": "2024-06-12T06:50:00.332402Z"
        },
        "trusted": true,
        "outputId": "b677b4cf-1d14-4f08-efbc-6abe79829fbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 42,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<All keys matched successfully>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Limpiar ram de cuda\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "Ud9j-oam6egk",
        "execution": {
          "iopub.status.busy": "2024-06-12T06:50:03.072354Z",
          "iopub.execute_input": "2024-06-12T06:50:03.07307Z",
          "iopub.status.idle": "2024-06-12T06:50:03.090949Z",
          "shell.execute_reply.started": "2024-06-12T06:50:03.073037Z",
          "shell.execute_reply": "2024-06-12T06:50:03.089912Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluaci칩n"
      ],
      "metadata": {
        "id": "37IjYq-_d5Pv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prueba_loss, prueba_precision, prueba_recall, prueba_f1 = evaluate(\n",
        "    model, dataloader_test, model_criterion)\n",
        "\n",
        "print(\n",
        "    f'Val. Loss: {prueba_loss:.3f} |  Val. f1: {prueba_f1:.2f} | Val. precision: {prueba_precision:.2f} | Val. recall: {prueba_recall:.2f}'\n",
        ")"
      ],
      "metadata": {
        "id": "kGz_8OB7eItO",
        "outputId": "9ae21334-bf79-4a2e-bfde-0646dda305d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.status.busy": "2024-06-12T06:50:08.503998Z",
          "iopub.execute_input": "2024-06-12T06:50:08.504358Z",
          "iopub.status.idle": "2024-06-12T06:50:09.076627Z",
          "shell.execute_reply.started": "2024-06-12T06:50:08.504329Z",
          "shell.execute_reply": "2024-06-12T06:50:09.075681Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Val. Loss: 0.356 |  Val. f1: 0.76 | Val. precision: 0.81 | Val. recall: 0.72\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### An치lisis"
      ],
      "metadata": {
        "id": "pURRQLkReNMY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las modificaciones realizadas en el modelo experimental, que incluyen la utilizaci칩n de embeddings pre-entrenados, la capa GRU bidireccional y la adici칩n de dropout, han mejorado significativamente el rendimiento en comparaci칩n con el modelo baseline. Las m칠tricas muestran que la p칠rdida disminuy칩 de 0.393 a 0.356, indicando un mejor ajuste a los datos de test. El F1-score aument칩 de 0.73 a 0.76, reflejando un mejor equilibrio entre precisi칩n y recall. La precisi칩n mejor칩 notablemente de 0.76 a 0.81, lo que sugiere que el modelo GRU tiene una mayor proporci칩n de predicciones correctas entre todas las predicciones hechas. Aunque el recall mostr칩 una mejora marginal de 0.71 a 0.72, este aumento indica que el modelo es un poco m치s eficaz en la identificaci칩n de todas las entidades relevantes en los datos. En general, estos cambios han permitido capturar mejor las relaciones contextuales en el texto, mejorando tanto la precisi칩n como la capacidad de generalizaci칩n del modelo."
      ],
      "metadata": {
        "id": "wfTrOktPeSB7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Experimento 2**"
      ],
      "metadata": {
        "id": "JIFrDPaGej4y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Explicaci칩n"
      ],
      "metadata": {
        "id": "M-dsNSEdej4z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cambios con respecto al modelo baseline:\n",
        "\n",
        "- Utilizaci칩n de embeddings pre-entrenados de \"Chilean Waiting List\".\n",
        "- Aumento del n칰mero de capas LSTM a dos.\n",
        "- Introducci칩n de una capa de dropout con una tasa del 0.5.\n",
        "- Incorporaci칩n de bidireccionalidad a las capas LSTM.\n",
        "\n",
        "\n",
        " En este experimento, se integraron embeddings pre-entrenados de \"Chilean Waiting List\", lo que no solo enriquece la calidad de las representaciones de las palabras, sino que tambi칠n acelera el proceso de entrenamiento al proporcionar un punto de partida s칩lido. Adem치s, se increment칩 la complejidad del modelo al aumentar el n칰mero de capas LSTM a dos, lo que le otorga una mayor capacidad para capturar relaciones m치s complejas en los datos de entrada. La introducci칩n de una capa de dropout con una tasa del 0.5 contribuy칩 a regularizar el proceso de entrenamiento, ayudando a controlar el sobreajuste y mejorando la capacidad de generalizaci칩n del modelo. Por 칰ltimo, la adici칩n de bidireccionalidad a las capas LSTM permiti칩 que el modelo capture informaci칩n contextual tanto del pasado como del futuro en la secuencia de texto, enriqueciendo as칤 su capacidad para reconocer y clasificar entidades nombradas con mayor precisi칩n y eficacia."
      ],
      "metadata": {
        "id": "c7JD-PzGej4z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Implementaci칩n"
      ],
      "metadata": {
        "id": "PKZIGOUpej4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NER_RNN_PRETRAINED(nn.Module):\n",
        "      \"\"\"\n",
        "      Modelo de Recurrent Neural Netowork (RNN) para Name Entity Recognition (NER)\n",
        "      utilizando embeddings pre-entrenados.\n",
        "\n",
        "      Parameters\n",
        "      ----------\n",
        "      pretrained_embeddings : Tensor\n",
        "            Tensor con los embeddings pre-entrenados.\n",
        "      embedding_dim : int\n",
        "            Dimensi칩n de los embeddings.\n",
        "      hidden_dim : int\n",
        "            Dimensi칩n de las capas ocultas de la LSTM.\n",
        "      output_dim : int\n",
        "            Dimensi칩n de la capa de salida.\n",
        "      n_layers : int\n",
        "            N칰mero de capas en la LSTM.\n",
        "      bidirectional : bool\n",
        "            Si la LSTM es bidireccional o no.\n",
        "      dropout : float\n",
        "            Tasa de dropout.\n",
        "      pad_idx : int\n",
        "            칈ndice de padding en los embeddings.\n",
        "      \"\"\"\n",
        "      def __init__(self,\n",
        "                  pretrained_embeddings,\n",
        "                  embedding_dim,\n",
        "                  hidden_dim,\n",
        "                  output_dim,\n",
        "                  n_layers,\n",
        "                  bidirectional,\n",
        "                  dropout,\n",
        "                  pad_idx\n",
        "                  ):\n",
        "\n",
        "          super().__init__()\n",
        "\n",
        "          # Capa de embedding usando embeddings pre-entrenados\n",
        "          self.embedding = nn.Embedding.from_pretrained(\n",
        "                                                        pretrained_embeddings,\n",
        "                                                        freeze=False,\n",
        "                                                        padding_idx=pad_idx\n",
        "                                                        )\n",
        "\n",
        "          # Capa LSTM\n",
        "          self.lstm = nn.LSTM(\n",
        "                              embedding_dim,\n",
        "                              hidden_dim,\n",
        "                              num_layers=n_layers,\n",
        "                              bidirectional=bidirectional,\n",
        "                              dropout = dropout if n_layers > 1 else 0\n",
        "                              )\n",
        "\n",
        "          # Capa de salida\n",
        "          self.fc = nn.Linear(\n",
        "                              hidden_dim * 2 if bidirectional else hidden_dim,\n",
        "                              output_dim\n",
        "                              )\n",
        "\n",
        "          # Capa de Dropout\n",
        "          self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "      def forward(self, text):\n",
        "          \"\"\"\n",
        "          Define el paso hacia adelante de la red.\n",
        "\n",
        "          Parameters\n",
        "          ----------\n",
        "          text : Tensor\n",
        "              Tensor de entrada de tama침o [sent len, batch size].\n",
        "\n",
        "          Returns\n",
        "          -------\n",
        "          Tensor :\n",
        "              Predicciones de la red de tama침o [sent len, batch size, output dim].\n",
        "          \"\"\"\n",
        "          #text = [sent len, batch size]\n",
        "\n",
        "          # Aplicar embeddings y dropout\n",
        "          embedded = self.dropout(self.embedding(text)) # embedded = [sent len, batch size, emb dim]\n",
        "\n",
        "          # Pasar los embeddings por la LSTM\n",
        "          outputs, (hidden, cell) = self.lstm(embedded)\n",
        "          # outputs = [sent len, batch size, hid dim * n directions]\n",
        "          # hidden/cell = [n layers * n directions, batch size, hid dim]\n",
        "\n",
        "          # Pasar las salidas de la LSTM por la capa de dropout y la capa lineal\n",
        "          predictions = self.fc(self.dropout(outputs)) # predictions = [sent len, batch size, output dim]\n",
        "\n",
        "          return predictions"
      ],
      "metadata": {
        "id": "B_Uyw10-ej40",
        "execution": {
          "iopub.status.busy": "2024-06-12T07:54:58.482146Z",
          "iopub.execute_input": "2024-06-12T07:54:58.482735Z",
          "iopub.status.idle": "2024-06-12T07:54:58.493061Z",
          "shell.execute_reply.started": "2024-06-12T07:54:58.482702Z",
          "shell.execute_reply": "2024-06-12T07:54:58.492131Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "0GpRIBi5_L2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ruta al archivo de embeddings pre-entrenados\n",
        "pretrained_embedding_path = '/content/drive/MyDrive/cwlce.vec'\n",
        "\n",
        "# Cargar embeddings pre-entrenados en formato word2vec\n",
        "word_vectors = KeyedVectors.load_word2vec_format(pretrained_embedding_path, binary=False)\n",
        "\n",
        "# Obtener vocabulario\n",
        "vocab = TEXT.vocab\n",
        "\n",
        "count=[]\n",
        "# Asignar embeddings pre-entrenados a los tokens del vocabulario\n",
        "for token, idx in vocab.get_stoi().items():\n",
        "    # Verificar si el token est치 en los embeddings pre-entrenados\n",
        "    if token.lower() in word_vectors.key_to_index:\n",
        "        count.append(idx)\n",
        "print(f\"Cantidad de tokens coincidentes: {len(count)}\")"
      ],
      "metadata": {
        "id": "L6O9zX02_MQs",
        "execution": {
          "iopub.status.busy": "2024-06-12T07:55:02.11504Z",
          "iopub.execute_input": "2024-06-12T07:55:02.115451Z",
          "iopub.status.idle": "2024-06-12T07:55:17.487778Z",
          "shell.execute_reply.started": "2024-06-12T07:55:02.115418Z",
          "shell.execute_reply": "2024-06-12T07:55:17.486793Z"
        },
        "trusted": true,
        "outputId": "72ae3cca-9a98-4f6f-be46-0a370234c7fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Cantidad de tokens coincidentes: 12947\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dimensi칩n de los embeddings pre-entrenados\n",
        "embedding_dim = word_vectors.vector_size\n",
        "\n",
        "# Inicializar la matriz de embeddings con ceros\n",
        "embedding_matrix = torch.zeros(len(vocab), embedding_dim)\n",
        "\n",
        "# Asignar embeddings pre-entrenados a los tokens del vocabulario\n",
        "for token, idx in vocab.get_stoi().items():\n",
        "    # Verificar si el token est치 en los embeddings pre-entrenados\n",
        "    if token.lower() in word_vectors.key_to_index:\n",
        "        embedding_matrix[idx] = torch.tensor(np.copy(word_vectors[token.lower()]), dtype=torch.float)\n",
        "    elif token == '<PAD>':\n",
        "        # Si el token es '<PAD>', asignar un vector de ceros\n",
        "        embedding_matrix[idx] = torch.zeros(embedding_dim)\n",
        "    else:\n",
        "        # Si el token no est치 en los embeddings pre-entrenados, asignar un vector aleatorio\n",
        "        embedding_matrix[idx] = torch.randn(embedding_dim)"
      ],
      "metadata": {
        "id": "RFB2Ivsr_VD4",
        "execution": {
          "iopub.status.busy": "2024-06-12T07:55:44.450143Z",
          "iopub.execute_input": "2024-06-12T07:55:44.451019Z",
          "iopub.status.idle": "2024-06-12T07:55:44.876701Z",
          "shell.execute_reply.started": "2024-06-12T07:55:44.450985Z",
          "shell.execute_reply": "2024-06-12T07:55:44.875822Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# INPUT_DIM = len(TEXT.vocab)\n",
        "PRETRAINED_EMBEDDINGS = embedding_matrix # Utilizamos la matriz de embeddings preentrenados creada anteriormente\n",
        "EMBEDDING_DIM = embedding_dim # Dimensi칩n de los embeddings\n",
        "HIDDEN_DIM = 256 # Dimensi칩n de las capas LSTM\n",
        "OUTPUT_DIM = len(NER_TAGS.vocab) # N칰mero de clases\n",
        "\n",
        "N_LAYERS = 2 # N칰mero de capas en la LSTM\n",
        "DROPOUT = 0.5 # Tasa de dropout\n",
        "BIDIRECTIONAL = True # Indicador de si la LSTM es bidireccional\n",
        "\n",
        "# Creamos el modelo\n",
        "model_2 = NER_RNN_PRETRAINED(pretrained_embeddings=PRETRAINED_EMBEDDINGS,\n",
        "                            embedding_dim=EMBEDDING_DIM,\n",
        "                            hidden_dim=HIDDEN_DIM,\n",
        "                            output_dim=OUTPUT_DIM,\n",
        "                            n_layers=N_LAYERS,\n",
        "                            bidirectional=BIDIRECTIONAL,\n",
        "                            dropout=DROPOUT,\n",
        "                            pad_idx=PAD_IDX)\n",
        "\n",
        "# Nombre que tendr치 el modelo guardado\n",
        "model_2_name = 'experimento_2'\n",
        "# N칰mero de 칠pocas para entrenar el modelo\n",
        "model_2_n_epochs = 10"
      ],
      "metadata": {
        "id": "CWvjvf8P_YqC",
        "execution": {
          "iopub.status.busy": "2024-06-12T06:52:06.900154Z",
          "iopub.execute_input": "2024-06-12T06:52:06.900499Z",
          "iopub.status.idle": "2024-06-12T06:52:06.930455Z",
          "shell.execute_reply.started": "2024-06-12T06:52:06.900474Z",
          "shell.execute_reply": "2024-06-12T06:52:06.929768Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss: Cross Entropy\n",
        "TAG_PAD_IDX = NER_TAGS.vocab.get_stoi()['<PAD>'] # Definir el 칤ndice de padding para las etiquetas\n",
        "model_2_criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX) # Definir la funci칩n de p칠rdida ignorando el 칤ndice de padding"
      ],
      "metadata": {
        "id": "hRamlYHv_hBz",
        "execution": {
          "iopub.status.busy": "2024-06-12T06:52:12.310617Z",
          "iopub.execute_input": "2024-06-12T06:52:12.310983Z",
          "iopub.status.idle": "2024-06-12T06:52:12.315994Z",
          "shell.execute_reply.started": "2024-06-12T06:52:12.310954Z",
          "shell.execute_reply": "2024-06-12T06:52:12.314893Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Asignar el modelo, el nombre del modelo, la funci칩n de p칠rdida y el n칰mero de 칠pocas de entrenamiento\n",
        "model = model_2\n",
        "model_name = model_2_name\n",
        "model_criterion = model_2_criterion\n",
        "model_n_epochs = model_2_n_epochs\n",
        "\n",
        "# Imprimir el n칰mero de par치metros entrenables en el modelo actual\n",
        "print(f'El modelo actual tiene {count_parameters(model):,} par치metros entrenables.')"
      ],
      "metadata": {
        "id": "Ux_TO-vp_jLC",
        "execution": {
          "iopub.status.busy": "2024-06-12T06:52:15.369942Z",
          "iopub.execute_input": "2024-06-12T06:52:15.370293Z",
          "iopub.status.idle": "2024-06-12T06:52:15.376033Z",
          "shell.execute_reply.started": "2024-06-12T06:52:15.370265Z",
          "shell.execute_reply": "2024-06-12T06:52:15.375068Z"
        },
        "trusted": true,
        "outputId": "02908c69-e75a-4661-c2cc-bd3b3f117708"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "El modelo actual tiene 7,674,700 par치metros entrenables.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicar la inicializaci칩n de pesos al modelo\n",
        "model.apply(init_weights)"
      ],
      "metadata": {
        "id": "ezXpvG3R_pg8",
        "execution": {
          "iopub.status.busy": "2024-06-12T06:52:19.424033Z",
          "iopub.execute_input": "2024-06-12T06:52:19.424397Z",
          "iopub.status.idle": "2024-06-12T06:52:19.540198Z",
          "shell.execute_reply.started": "2024-06-12T06:52:19.424368Z",
          "shell.execute_reply": "2024-06-12T06:52:19.539304Z"
        },
        "trusted": true,
        "outputId": "93b98931-bdd0-46e8-dd84-e1983efd4d6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 51,
          "output_type": "execute_result",
          "data": {
            "text/plain": "NER_RNN_PRETRAINED(\n  (embedding): Embedding(16496, 300, padding_idx=0)\n  (lstm): LSTM(300, 256, num_layers=2, dropout=0.5, bidirectional=True)\n  (fc): Linear(in_features=512, out_features=12, bias=True)\n  (dropout): Dropout(p=0.5, inplace=False)\n)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizador\n",
        "model_optimizer = optim.Adam(model.parameters()) # SGD, AdamW"
      ],
      "metadata": {
        "id": "dR01x6P9_rYa",
        "execution": {
          "iopub.status.busy": "2024-06-12T06:52:27.421554Z",
          "iopub.execute_input": "2024-06-12T06:52:27.422363Z",
          "iopub.status.idle": "2024-06-12T06:52:27.427212Z",
          "shell.execute_reply.started": "2024-06-12T06:52:27.422327Z",
          "shell.execute_reply": "2024-06-12T06:52:27.426272Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enviar el modelo y la funci칩n de p칠rdida a la GPU (si est치 disponible)\n",
        "model = model.to(device)\n",
        "model_criterion = model_criterion.to(device)"
      ],
      "metadata": {
        "id": "Jug3dHD9_tVs",
        "execution": {
          "iopub.status.busy": "2024-06-12T06:52:31.987268Z",
          "iopub.execute_input": "2024-06-12T06:52:31.988063Z",
          "iopub.status.idle": "2024-06-12T06:52:32.001913Z",
          "shell.execute_reply.started": "2024-06-12T06:52:31.988028Z",
          "shell.execute_reply": "2024-06-12T06:52:32.001166Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_valid_loss = float('inf') # Inicializar la mejor p칠rdida de validaci칩n como infinita\n",
        "\n",
        "# Bucle de entrenamiento y validaci칩n para cada 칠poca\n",
        "for epoch in range(model_n_epochs):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Entrenar el modelo con el conjunto de entrenamiento\n",
        "    train_loss, train_precision, train_recall, train_f1 = train(\n",
        "        model, dataloader_train, model_optimizer, model_criterion)\n",
        "\n",
        "    # Evaluar el modelo en el conjunto de validaci칩n\n",
        "    valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(\n",
        "        model, dataloader_dev, model_criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "    # Calcular el tiempo de la 칠poca (minutos y segundos)\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    # Guardar el modelo si la p칠rdida de validaci칩n es la mejor obtenida hasta ahora\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), '{}.pt'.format(model_name))\n",
        "\n",
        "    # Imprimir resultados de la 칠poca\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(\n",
        "        f'\\tTrain Loss: {train_loss:.3f} | Train f1: {train_f1:.2f} | Train precision: {train_precision:.2f} | Train recall: {train_recall:.2f}'\n",
        "    )\n",
        "    print(\n",
        "        f'\\t Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} |  Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}'\n",
        "    )"
      ],
      "metadata": {
        "id": "b9VQcV3z_wOU",
        "execution": {
          "iopub.status.busy": "2024-06-12T06:52:36.058674Z",
          "iopub.execute_input": "2024-06-12T06:52:36.05906Z",
          "iopub.status.idle": "2024-06-12T06:53:56.720424Z",
          "shell.execute_reply.started": "2024-06-12T06:52:36.059028Z",
          "shell.execute_reply": "2024-06-12T06:53:56.719449Z"
        },
        "trusted": true,
        "outputId": "ef343998-cdeb-448e-b181-82f0ac5aca86"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch: 01 | Epoch Time: 0m 8s\n\tTrain Loss: 0.775 | Train f1: 0.43 | Train precision: 0.61 | Train recall: 0.35\n\t Val. Loss: 0.457 |  Val. f1: 0.69 |  Val. precision: 0.76 | Val. recall: 0.63\nEpoch: 02 | Epoch Time: 0m 8s\n\tTrain Loss: 0.414 | Train f1: 0.70 | Train precision: 0.77 | Train recall: 0.65\n\t Val. Loss: 0.358 |  Val. f1: 0.75 |  Val. precision: 0.78 | Val. recall: 0.72\nEpoch: 03 | Epoch Time: 0m 7s\n\tTrain Loss: 0.276 | Train f1: 0.80 | Train precision: 0.82 | Train recall: 0.77\n\t Val. Loss: 0.342 |  Val. f1: 0.76 |  Val. precision: 0.80 | Val. recall: 0.73\nEpoch: 04 | Epoch Time: 0m 8s\n\tTrain Loss: 0.201 | Train f1: 0.85 | Train precision: 0.86 | Train recall: 0.84\n\t Val. Loss: 0.355 |  Val. f1: 0.78 |  Val. precision: 0.81 | Val. recall: 0.75\nEpoch: 05 | Epoch Time: 0m 7s\n\tTrain Loss: 0.150 | Train f1: 0.89 | Train precision: 0.89 | Train recall: 0.89\n\t Val. Loss: 0.385 |  Val. f1: 0.77 |  Val. precision: 0.81 | Val. recall: 0.75\nEpoch: 06 | Epoch Time: 0m 7s\n\tTrain Loss: 0.120 | Train f1: 0.91 | Train precision: 0.91 | Train recall: 0.91\n\t Val. Loss: 0.401 |  Val. f1: 0.78 |  Val. precision: 0.81 | Val. recall: 0.76\nEpoch: 07 | Epoch Time: 0m 7s\n\tTrain Loss: 0.099 | Train f1: 0.93 | Train precision: 0.93 | Train recall: 0.92\n\t Val. Loss: 0.410 |  Val. f1: 0.78 |  Val. precision: 0.79 | Val. recall: 0.77\nEpoch: 08 | Epoch Time: 0m 7s\n\tTrain Loss: 0.084 | Train f1: 0.94 | Train precision: 0.94 | Train recall: 0.94\n\t Val. Loss: 0.444 |  Val. f1: 0.77 |  Val. precision: 0.76 | Val. recall: 0.78\nEpoch: 09 | Epoch Time: 0m 7s\n\tTrain Loss: 0.068 | Train f1: 0.95 | Train precision: 0.95 | Train recall: 0.95\n\t Val. Loss: 0.466 |  Val. f1: 0.77 |  Val. precision: 0.77 | Val. recall: 0.78\nEpoch: 10 | Epoch Time: 0m 7s\n\tTrain Loss: 0.057 | Train f1: 0.96 | Train precision: 0.96 | Train recall: 0.96\n\t Val. Loss: 0.483 |  Val. f1: 0.78 |  Val. precision: 0.78 | Val. recall: 0.78\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el mejor modelo entrenado\n",
        "model.load_state_dict(torch.load('{}.pt'.format(model_name)))"
      ],
      "metadata": {
        "id": "X7J8Xm3x_y5u",
        "execution": {
          "iopub.status.busy": "2024-06-12T06:54:10.059341Z",
          "iopub.execute_input": "2024-06-12T06:54:10.059694Z",
          "iopub.status.idle": "2024-06-12T06:54:10.084283Z",
          "shell.execute_reply.started": "2024-06-12T06:54:10.059664Z",
          "shell.execute_reply": "2024-06-12T06:54:10.083374Z"
        },
        "trusted": true,
        "outputId": "c8d49397-9292-4242-f3fc-234a6d5c1a66"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 55,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<All keys matched successfully>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Limpiar ram de cuda\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "QppN5J-N_0k-",
        "execution": {
          "iopub.status.busy": "2024-06-12T06:54:12.765611Z",
          "iopub.execute_input": "2024-06-12T06:54:12.765978Z",
          "iopub.status.idle": "2024-06-12T06:54:12.784725Z",
          "shell.execute_reply.started": "2024-06-12T06:54:12.765948Z",
          "shell.execute_reply": "2024-06-12T06:54:12.783749Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluaci칩n"
      ],
      "metadata": {
        "id": "epaoMVyMej40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prueba_loss, prueba_precision, prueba_recall, prueba_f1 = evaluate(\n",
        "    model, dataloader_test, model_criterion)\n",
        "\n",
        "print(\n",
        "    f'Test. Loss: {prueba_loss:.3f} |  Test. f1: {prueba_f1:.2f} | Test. precision: {prueba_precision:.2f} | Test. recall: {prueba_recall:.2f}'\n",
        ")"
      ],
      "metadata": {
        "id": "BF8M8iLGej40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "799d8aec-ba5c-49a8-df45-f1daa7a5771e",
        "execution": {
          "iopub.status.busy": "2024-06-12T06:54:19.435569Z",
          "iopub.execute_input": "2024-06-12T06:54:19.436002Z",
          "iopub.status.idle": "2024-06-12T06:54:20.184458Z",
          "shell.execute_reply.started": "2024-06-12T06:54:19.43597Z",
          "shell.execute_reply": "2024-06-12T06:54:20.183524Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Test. Loss: 0.363 |  Test. f1: 0.76 | Test. precision: 0.79 | Test. recall: 0.73\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### An치lisis"
      ],
      "metadata": {
        "id": "bqymD_Nuej41"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El segundo experimento mostr칩 mejoras significativas en comparaci칩n con el modelo baseline. La p칠rdida se redujo de 0.393 a 0.363, indicando que el modelo del experimento tiene un mejor ajuste a los datos de prueba. El F1 score aument칩 de 0.73 a 0.76, reflejando una mejora en el balance entre precisi칩n y recall, mientras que la precisi칩n mejor칩 de 0.76 a 0.79, sugiriendo que el modelo del experimento hace m치s predicciones correctas entre todas las predicciones realizadas. Adem치s, el recall increment칩 de 0.71 a 0.73, demostrando que el modelo del experimento es m치s eficaz en la identificaci칩n de las entidades relevantes.\n",
        "\n",
        "Estas mejoras se justifican por las modificaciones introducidas. Los embeddings pre-entrenados aportaron representaciones vectoriales ricas y espec칤ficas del dominio, mejorando la comprensi칩n contextual del modelo; el aumento a dos capas LSTM permiti칩 capturar caracter칤sticas m치s complejas y profundas del texto. La introducci칩n de una capa de dropout con una tasa del 0.5 ayud칩 a prevenir el sobreajuste, forzando al modelo a generalizar mejor durante el entrenamiento. Finalmente, la bidireccionalidad en las capas LSTM permiti칩 procesar la secuencia en ambas direcciones, capturando informaci칩n contextual completa y mejorando la identificaci칩n de entidades. Estas mejoras combinadas resultaron en una mejor capacidad del modelo para aprender y generalizar, reflejadas en las m칠tricas de desempe침o mejoradas."
      ],
      "metadata": {
        "id": "88tsCz4eej41"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Experimento 3**"
      ],
      "metadata": {
        "id": "ZcPtyefAenbW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Explicaci칩n"
      ],
      "metadata": {
        "id": "eYUFyLMJenbX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cambios con respecto al modelo baseline:\n",
        "\n",
        "- Utilizaci칩n de embeddings pre-entrenados de \"Chilean Waiting List\".\n",
        "- Aumento del tama침o de la capa LSTM de 256 a 512.\n",
        "- Introducci칩n de un mecanismo de atenci칩n a la capa LSTM.\n",
        "- Utilizaci칩n de 2 capas LSTM en lugar de una.\n",
        "- Aumento de la tasa de dropout de 0 (sin dropout) a 0.7.\n",
        "- Incorporaci칩n de bidireccionalidad a las capas LSTM.\n",
        "- Aumento del n칰mero de 칠pocas de entrenamiento de 20 a 30.\n",
        "- Cambios en el learning rate y weight decay del optimizador: de 1e-3 a 9e-4 y de 0 a 1e-5, respectivamente.\n",
        "\n",
        "La utilizaci칩n de embeddings pre-entrenados de \"Chilean Waiting List\" proporciona al modelo representaciones m치s ricas y espec칤ficas del dominio, lo que facilita la comprensi칩n contextual del texto. El aumento del tama침o de la capa LSTM de 256 a 512 permite al modelo capturar y procesar de manera m치s efectiva la informaci칩n en cada paso de tiempo. La introducci칩n de un mecanismo de atenci칩n a la capa LSTM mejora la capacidad del modelo para enfocarse en partes importantes de la secuencia de entrada, permitiendo una mayor flexibilidad y precisi칩n en la predicci칩n. Adem치s, la utilizaci칩n de dos capas LSTM en lugar de una proporciona al modelo una mayor capacidad de representaci칩n y aprendizaje de caracter칤sticas complejas en los datos. El aumento de la tasa de dropout a 0.7 y la incorporaci칩n de bidireccionalidad a las capas LSTM ayudan a prevenir el sobreajuste del modelo y a capturar relaciones contextuales m치s amplias en el texto. Finalmente, el incremento en el n칰mero de 칠pocas de entrenamiento y los ajustes en el learning rate y weight decay del optimizador permiten un entrenamiento m치s robusto y una convergencia m치s eficiente del modelo hacia 칩ptimos locales de rendimiento."
      ],
      "metadata": {
        "id": "fuI3TaAhenbY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Implementaci칩n"
      ],
      "metadata": {
        "id": "800wWbuGenbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NER_RNN_Attention(nn.Module):\n",
        "      \"\"\"\n",
        "      Modelo de Recurrent Neural Network (RNN) junto a Attention layers para Name Entity Recognition (NER)\n",
        "      utilizando embeddings pre-entrenados.\n",
        "\n",
        "      Parameters\n",
        "      ----------\n",
        "      pretrained_embeddings : Tensor\n",
        "            Tensor con los embeddings pre-entrenados.\n",
        "      embedding_dim : int\n",
        "            Dimensi칩n de los embeddings.\n",
        "      hidden_dim : int\n",
        "            Dimensi칩n de las capas ocultas de la LSTM.\n",
        "      output_dim : int\n",
        "            Dimensi칩n de la capa de salida.\n",
        "      n_layers : int\n",
        "            N칰mero de capas en la LSTM.\n",
        "      bidirectional : bool\n",
        "            Si la LSTM es bidireccional o no.\n",
        "      dropout : float\n",
        "            Tasa de dropout.\n",
        "      pad_idx : int\n",
        "            칈ndice de padding en los embeddings.\n",
        "      \"\"\"\n",
        "      def __init__(self,\n",
        "                  pretrained_embeddings,\n",
        "                  embedding_dim,\n",
        "                  hidden_dim,\n",
        "                  output_dim,\n",
        "                  n_layers,\n",
        "                  bidirectional,\n",
        "                  dropout,\n",
        "                  pad_idx\n",
        "                  ):\n",
        "\n",
        "          super().__init__()\n",
        "\n",
        "          self.embedding_dim = embedding_dim\n",
        "\n",
        "          self.hidden_dim = hidden_dim\n",
        "\n",
        "          self.output_dim = output_dim\n",
        "\n",
        "          # Capa de embedding usando embeddings pre-entrenados\n",
        "          self.embedding = nn.Embedding.from_pretrained(\n",
        "                                                        pretrained_embeddings,\n",
        "                                                        freeze=False,\n",
        "                                                        padding_idx=pad_idx\n",
        "                                                        )\n",
        "\n",
        "          # Capa LSTM\n",
        "          self.lstm = nn.LSTM(\n",
        "                              self.embedding_dim,\n",
        "                              self.hidden_dim,\n",
        "                              num_layers=n_layers,\n",
        "                              bidirectional=bidirectional,\n",
        "                              dropout=dropout if n_layers > 1 else 0\n",
        "                              )\n",
        "\n",
        "          # Capa de atenci칩n\n",
        "          self.attention = nn.Linear(self.hidden_dim * 2 if bidirectional else self.hidden_dim, 1)\n",
        "\n",
        "          # Capa de salida\n",
        "          self.fc = nn.Linear(\n",
        "                              self.hidden_dim * 2 if bidirectional else self.hidden_dim,\n",
        "                              self.output_dim\n",
        "                              )\n",
        "\n",
        "          # Capa de Dropout\n",
        "          self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "      def forward(self, text):\n",
        "          \"\"\"\n",
        "          Define el paso hacia adelante de la red.\n",
        "\n",
        "          Parameters\n",
        "          ----------\n",
        "          text : Tensor\n",
        "              Tensor de entrada de tama침o [sent len, batch size].\n",
        "\n",
        "          Returns\n",
        "          -------\n",
        "          Tensor :\n",
        "              Predicciones de la red de tama침o [sent len, batch size, output dim].\n",
        "          \"\"\"\n",
        "\n",
        "          #text = [sent len, batch size]\n",
        "\n",
        "          # Aplicar embeddings y dropout\n",
        "          embedded = self.dropout(self.embedding(text)) #embedded = [sent len, batch size, emb dim]\n",
        "\n",
        "          # Pasar los embeddings por la LSTM\n",
        "          outputs, (hidden, cell) = self.lstm(embedded)\n",
        "          #output = [sent len, batch size, hid dim * n directions]\n",
        "          #hidden/cell = [n layers * n directions, batch size, hid dim]\n",
        "\n",
        "          # Calcular las atenciones\n",
        "          attn_weights = self.attention(outputs).squeeze(-1) # attn_weights = [sent len, batch size]\n",
        "          attn_weights = F.softmax(attn_weights, dim=0) # attn_weights = [sent len, batch size]\n",
        "\n",
        "          # Multiplicar las atenciones por las salidas de la LSTM\n",
        "          weighted_outputs = outputs * attn_weights.unsqueeze(-1) # weighted_outputs = [sent len, batch size, hid dim * n directions]\n",
        "\n",
        "          # Pasar las salidas ponderadas por la capa de dropout y la capa lineal\n",
        "          predictions = self.fc(self.dropout(weighted_outputs)) # predictions = [sent len, batch size, output dim]\n",
        "\n",
        "          return predictions"
      ],
      "metadata": {
        "id": "zON_wa1penbY",
        "execution": {
          "iopub.status.busy": "2024-06-12T07:55:55.014024Z",
          "iopub.execute_input": "2024-06-12T07:55:55.014404Z",
          "iopub.status.idle": "2024-06-12T07:55:55.027751Z",
          "shell.execute_reply.started": "2024-06-12T07:55:55.014373Z",
          "shell.execute_reply": "2024-06-12T07:55:55.026903Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "1NnJEyAXATC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ruta al archivo de embeddings pre-entrenados\n",
        "pretrained_embedding_path = '/kaggle/working/cwlce.vec'\n",
        "\n",
        "# Cargar embeddings pre-entrenados en formato word2vec\n",
        "word_vectors = KeyedVectors.load_word2vec_format(pretrained_embedding_path, binary=False)\n",
        "\n",
        "# Obtener vocabulario\n",
        "vocab = TEXT.vocab\n",
        "\n",
        "count=[]\n",
        "# Asignar embeddings pre-entrenados a los tokens del vocabulario\n",
        "for token, idx in vocab.get_stoi().items():\n",
        "    # Verificar si el token est치 en los embeddings pre-entrenados\n",
        "    if token.lower() in word_vectors.key_to_index:\n",
        "        count.append(idx)\n",
        "print(f\"Cantidad de tokens coincidentes: {len(count)}\")"
      ],
      "metadata": {
        "id": "FLBSfJczAbNq",
        "execution": {
          "iopub.status.busy": "2024-06-12T08:27:06.531215Z",
          "iopub.execute_input": "2024-06-12T08:27:06.531693Z",
          "iopub.status.idle": "2024-06-12T08:27:22.142245Z",
          "shell.execute_reply.started": "2024-06-12T08:27:06.531646Z",
          "shell.execute_reply": "2024-06-12T08:27:22.141311Z"
        },
        "trusted": true,
        "outputId": "2822b6ad-9f20-499a-ee4f-93c00b77a76b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Cantidad de tokens coincidentes: 12947\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dimensi칩n de los embeddings pre-entrenados\n",
        "embedding_dim = word_vectors.vector_size\n",
        "\n",
        "# Inicializar la matriz de embeddings con ceros\n",
        "embedding_matrix = torch.zeros(len(vocab), embedding_dim)\n",
        "\n",
        "# Asignar embeddings pre-entrenados a los tokens del vocabulario\n",
        "for token, idx in vocab.get_stoi().items():\n",
        "    # Verificar si el token est치 en los embeddings pre-entrenados\n",
        "    if token.lower() in word_vectors.key_to_index:\n",
        "        embedding_matrix[idx] = torch.tensor(np.copy(word_vectors[token.lower()]), dtype=torch.float)\n",
        "    elif token == '<PAD>':\n",
        "        # Si el token es '<PAD>', asignar un vector de ceros\n",
        "        embedding_matrix[idx] = torch.zeros(embedding_dim)\n",
        "    else:\n",
        "        # Si el token no est치 en los embeddings pre-entrenados, asignar un vector aleatorio\n",
        "        embedding_matrix[idx] = torch.randn(embedding_dim)"
      ],
      "metadata": {
        "id": "U0CuoZDNAeX8",
        "execution": {
          "iopub.status.busy": "2024-06-12T08:27:22.143783Z",
          "iopub.execute_input": "2024-06-12T08:27:22.144064Z",
          "iopub.status.idle": "2024-06-12T08:27:22.497125Z",
          "shell.execute_reply.started": "2024-06-12T08:27:22.14404Z",
          "shell.execute_reply": "2024-06-12T08:27:22.496311Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# INPUT_DIM = len(TEXT.vocab)\n",
        "PRETRAINED_EMBEDDINGS = embedding_matrix # Utilizamos la matriz de embeddings preentrenados creada anteriormente\n",
        "EMBEDDING_DIM = embedding_dim # Dimensi칩n de los embeddings\n",
        "HIDDEN_DIM = 512 #256 # Dimensi칩n de las capas LSTM\n",
        "OUTPUT_DIM = len(NER_TAGS.vocab) # N칰mero de clases\n",
        "\n",
        "N_LAYERS = 2 # N칰mero de capas en la LSTM\n",
        "DROPOUT = 0.7 # Tasa de dropout\n",
        "BIDIRECTIONAL = True # Indicador de si la LSTM es bidireccional\n",
        "\n",
        "# Creamos nuestro modelo\n",
        "model_3 = NER_RNN_Attention(pretrained_embeddings=PRETRAINED_EMBEDDINGS,\n",
        "                            embedding_dim=EMBEDDING_DIM,\n",
        "                            hidden_dim=HIDDEN_DIM,\n",
        "                            output_dim=OUTPUT_DIM,\n",
        "                            n_layers=N_LAYERS,\n",
        "                            bidirectional=BIDIRECTIONAL,\n",
        "                            dropout=DROPOUT,\n",
        "                            pad_idx=PAD_IDX)\n",
        "\n",
        "# Nombre que tendr치 el modelo guardado\n",
        "model_3_name = 'experimento_3'\n",
        "# N칰mero de 칠pocas para entrenar el modelo\n",
        "model_3_n_epochs = 30"
      ],
      "metadata": {
        "id": "1_rT6WpEAhGm",
        "execution": {
          "iopub.status.busy": "2024-06-12T08:27:22.498152Z",
          "iopub.execute_input": "2024-06-12T08:27:22.498414Z",
          "iopub.status.idle": "2024-06-12T08:27:22.591645Z",
          "shell.execute_reply.started": "2024-06-12T08:27:22.498392Z",
          "shell.execute_reply": "2024-06-12T08:27:22.590376Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss: Cross Entropy\n",
        "TAG_PAD_IDX = NER_TAGS.vocab.get_stoi()['<PAD>'] # Definir el 칤ndice de padding para las etiquetas\n",
        "model_3_criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX) # Definir la funci칩n de p칠rdida ignorando el 칤ndice de padding"
      ],
      "metadata": {
        "id": "QiTLwhrrAjkO",
        "execution": {
          "iopub.status.busy": "2024-06-12T08:28:02.188643Z",
          "iopub.execute_input": "2024-06-12T08:28:02.189513Z",
          "iopub.status.idle": "2024-06-12T08:28:02.194031Z",
          "shell.execute_reply.started": "2024-06-12T08:28:02.189478Z",
          "shell.execute_reply": "2024-06-12T08:28:02.193055Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Asignar el modelo, el nombre del modelo, la funci칩n de p칠rdida y el n칰mero de 칠pocas de entrenamiento\n",
        "model = model_3\n",
        "model_name = model_3_name\n",
        "model_criterion = model_3_criterion\n",
        "model_n_epochs = model_3_n_epochs\n",
        "\n",
        "# Imprimir el n칰mero de par치metros entrenables en el modelo actual\n",
        "print(f'El modelo actual tiene {count_parameters(model):,} par치metros entrenables.')"
      ],
      "metadata": {
        "id": "gA3xkjTyAloi",
        "execution": {
          "iopub.status.busy": "2024-06-12T08:28:03.725055Z",
          "iopub.execute_input": "2024-06-12T08:28:03.72563Z",
          "iopub.status.idle": "2024-06-12T08:28:03.73249Z",
          "shell.execute_reply.started": "2024-06-12T08:28:03.725582Z",
          "shell.execute_reply": "2024-06-12T08:28:03.730811Z"
        },
        "trusted": true,
        "outputId": "762c084f-6e44-451a-a49f-8ab770c02224"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "El modelo actual tiene 14,595,917 par치metros entrenables.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicar la inicializaci칩n de pesos al modelo\n",
        "model.apply(init_weights)"
      ],
      "metadata": {
        "id": "6PMGgVUFArao",
        "execution": {
          "iopub.status.busy": "2024-06-12T08:28:05.790445Z",
          "iopub.execute_input": "2024-06-12T08:28:05.791381Z",
          "iopub.status.idle": "2024-06-12T08:28:06.016274Z",
          "shell.execute_reply.started": "2024-06-12T08:28:05.79132Z",
          "shell.execute_reply": "2024-06-12T08:28:06.015308Z"
        },
        "trusted": true,
        "outputId": "1ca15cf1-9bb1-4803-8d2d-0b169c1d3057"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 73,
          "output_type": "execute_result",
          "data": {
            "text/plain": "NER_RNN_Attention(\n  (embedding): Embedding(16496, 300, padding_idx=0)\n  (lstm): LSTM(300, 512, num_layers=2, dropout=0.7, bidirectional=True)\n  (attention): Linear(in_features=1024, out_features=1, bias=True)\n  (fc): Linear(in_features=1024, out_features=12, bias=True)\n  (dropout): Dropout(p=0.7, inplace=False)\n)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizador\n",
        "model_optimizer = optim.Adam(model.parameters(), lr=9e-4, weight_decay=1e-5) # SGD, AdamW"
      ],
      "metadata": {
        "id": "xfsNvi7lAtnl",
        "execution": {
          "iopub.status.busy": "2024-06-12T08:28:10.938715Z",
          "iopub.execute_input": "2024-06-12T08:28:10.939549Z",
          "iopub.status.idle": "2024-06-12T08:28:10.94438Z",
          "shell.execute_reply.started": "2024-06-12T08:28:10.939517Z",
          "shell.execute_reply": "2024-06-12T08:28:10.943383Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enviar el modelo y la funci칩n de p칠rdida a la GPU (si est치 disponible)\n",
        "model = model.to(device)\n",
        "model_criterion = model_criterion.to(device)"
      ],
      "metadata": {
        "id": "n7-SvqLCAv6F",
        "execution": {
          "iopub.status.busy": "2024-06-12T08:28:12.237695Z",
          "iopub.execute_input": "2024-06-12T08:28:12.23803Z",
          "iopub.status.idle": "2024-06-12T08:28:12.258216Z",
          "shell.execute_reply.started": "2024-06-12T08:28:12.238005Z",
          "shell.execute_reply": "2024-06-12T08:28:12.257402Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_valid_loss = float('inf') # Inicializar la mejor p칠rdida de validaci칩n como infinita\n",
        "\n",
        "# Bucle de entrenamiento y validaci칩n para cada 칠poca\n",
        "for epoch in range(model_n_epochs):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Entrenar el modelo con el conjunto de entrenamiento\n",
        "    train_loss, train_precision, train_recall, train_f1 = train(\n",
        "        model, dataloader_train, model_optimizer, model_criterion)\n",
        "\n",
        "    # Evaluar el modelo en el conjunto de validaci칩n\n",
        "    valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(\n",
        "        model, dataloader_dev, model_criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "    # Calcular el tiempo de la 칠poca (minutos y segundos)\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    # Guardar el modelo si la p칠rdida de validaci칩n es la mejor obtenida hasta ahora\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), '{}.pt'.format(model_name))\n",
        "\n",
        "    # Imprimir resultados de la 칠poca\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(\n",
        "        f'\\tTrain Loss: {train_loss:.3f} | Train f1: {train_f1:.2f} | Train precision: {train_precision:.2f} | Train recall: {train_recall:.2f}'\n",
        "    )\n",
        "    print(\n",
        "        f'\\t Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} |  Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}'\n",
        "    )"
      ],
      "metadata": {
        "id": "4AmnE-cbCl_y",
        "execution": {
          "iopub.status.busy": "2024-06-12T08:28:14.456379Z",
          "iopub.execute_input": "2024-06-12T08:28:14.457202Z",
          "iopub.status.idle": "2024-06-12T08:36:04.102216Z",
          "shell.execute_reply.started": "2024-06-12T08:28:14.45717Z",
          "shell.execute_reply": "2024-06-12T08:36:04.101191Z"
        },
        "trusted": true,
        "outputId": "c4dd74fb-4225-43ac-bd4c-00e29eb3c0fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch: 01 | Epoch Time: 0m 15s\n\tTrain Loss: 1.263 | Train f1: 0.00 | Train precision: 0.00 | Train recall: 0.00\n\t Val. Loss: 1.022 |  Val. f1: 0.00 |  Val. precision: 0.00 | Val. recall: 0.00\nEpoch: 02 | Epoch Time: 0m 15s\n\tTrain Loss: 0.964 | Train f1: 0.00 | Train precision: 0.01 | Train recall: 0.00\n\t Val. Loss: 0.909 |  Val. f1: 0.00 |  Val. precision: 0.02 | Val. recall: 0.00\nEpoch: 03 | Epoch Time: 0m 15s\n\tTrain Loss: 0.847 | Train f1: 0.09 | Train precision: 0.25 | Train recall: 0.06\n\t Val. Loss: 0.792 |  Val. f1: 0.29 |  Val. precision: 0.49 | Val. recall: 0.21\nEpoch: 04 | Epoch Time: 0m 15s\n\tTrain Loss: 0.684 | Train f1: 0.38 | Train precision: 0.54 | Train recall: 0.30\n\t Val. Loss: 0.685 |  Val. f1: 0.42 |  Val. precision: 0.52 | Val. recall: 0.35\nEpoch: 05 | Epoch Time: 0m 15s\n\tTrain Loss: 0.576 | Train f1: 0.46 | Train precision: 0.58 | Train recall: 0.38\n\t Val. Loss: 0.629 |  Val. f1: 0.45 |  Val. precision: 0.52 | Val. recall: 0.39\nEpoch: 06 | Epoch Time: 0m 15s\n\tTrain Loss: 0.487 | Train f1: 0.55 | Train precision: 0.63 | Train recall: 0.49\n\t Val. Loss: 0.544 |  Val. f1: 0.61 |  Val. precision: 0.64 | Val. recall: 0.58\nEpoch: 07 | Epoch Time: 0m 15s\n\tTrain Loss: 0.400 | Train f1: 0.68 | Train precision: 0.73 | Train recall: 0.63\n\t Val. Loss: 0.494 |  Val. f1: 0.67 |  Val. precision: 0.71 | Val. recall: 0.64\nEpoch: 08 | Epoch Time: 0m 15s\n\tTrain Loss: 0.351 | Train f1: 0.72 | Train precision: 0.76 | Train recall: 0.69\n\t Val. Loss: 0.481 |  Val. f1: 0.69 |  Val. precision: 0.73 | Val. recall: 0.66\nEpoch: 09 | Epoch Time: 0m 15s\n\tTrain Loss: 0.302 | Train f1: 0.75 | Train precision: 0.78 | Train recall: 0.73\n\t Val. Loss: 0.455 |  Val. f1: 0.70 |  Val. precision: 0.74 | Val. recall: 0.67\nEpoch: 10 | Epoch Time: 0m 15s\n\tTrain Loss: 0.266 | Train f1: 0.79 | Train precision: 0.81 | Train recall: 0.76\n\t Val. Loss: 0.456 |  Val. f1: 0.73 |  Val. precision: 0.77 | Val. recall: 0.69\nEpoch: 11 | Epoch Time: 0m 15s\n\tTrain Loss: 0.234 | Train f1: 0.83 | Train precision: 0.85 | Train recall: 0.81\n\t Val. Loss: 0.478 |  Val. f1: 0.75 |  Val. precision: 0.79 | Val. recall: 0.71\nEpoch: 12 | Epoch Time: 0m 15s\n\tTrain Loss: 0.210 | Train f1: 0.85 | Train precision: 0.87 | Train recall: 0.83\n\t Val. Loss: 0.486 |  Val. f1: 0.74 |  Val. precision: 0.80 | Val. recall: 0.69\nEpoch: 13 | Epoch Time: 0m 15s\n\tTrain Loss: 0.186 | Train f1: 0.87 | Train precision: 0.89 | Train recall: 0.86\n\t Val. Loss: 0.451 |  Val. f1: 0.76 |  Val. precision: 0.79 | Val. recall: 0.73\nEpoch: 14 | Epoch Time: 0m 15s\n\tTrain Loss: 0.168 | Train f1: 0.88 | Train precision: 0.90 | Train recall: 0.87\n\t Val. Loss: 0.485 |  Val. f1: 0.76 |  Val. precision: 0.79 | Val. recall: 0.73\nEpoch: 15 | Epoch Time: 0m 15s\n\tTrain Loss: 0.159 | Train f1: 0.89 | Train precision: 0.90 | Train recall: 0.87\n\t Val. Loss: 0.456 |  Val. f1: 0.76 |  Val. precision: 0.79 | Val. recall: 0.74\nEpoch: 16 | Epoch Time: 0m 15s\n\tTrain Loss: 0.147 | Train f1: 0.90 | Train precision: 0.91 | Train recall: 0.88\n\t Val. Loss: 0.498 |  Val. f1: 0.75 |  Val. precision: 0.76 | Val. recall: 0.74\nEpoch: 17 | Epoch Time: 0m 15s\n\tTrain Loss: 0.139 | Train f1: 0.90 | Train precision: 0.91 | Train recall: 0.89\n\t Val. Loss: 0.531 |  Val. f1: 0.75 |  Val. precision: 0.78 | Val. recall: 0.73\nEpoch: 18 | Epoch Time: 0m 15s\n\tTrain Loss: 0.136 | Train f1: 0.90 | Train precision: 0.91 | Train recall: 0.89\n\t Val. Loss: 0.506 |  Val. f1: 0.76 |  Val. precision: 0.78 | Val. recall: 0.74\nEpoch: 19 | Epoch Time: 0m 15s\n\tTrain Loss: 0.125 | Train f1: 0.91 | Train precision: 0.92 | Train recall: 0.90\n\t Val. Loss: 0.482 |  Val. f1: 0.75 |  Val. precision: 0.77 | Val. recall: 0.74\nEpoch: 20 | Epoch Time: 0m 15s\n\tTrain Loss: 0.119 | Train f1: 0.91 | Train precision: 0.92 | Train recall: 0.90\n\t Val. Loss: 0.483 |  Val. f1: 0.75 |  Val. precision: 0.76 | Val. recall: 0.75\nEpoch: 21 | Epoch Time: 0m 15s\n\tTrain Loss: 0.113 | Train f1: 0.92 | Train precision: 0.93 | Train recall: 0.91\n\t Val. Loss: 0.545 |  Val. f1: 0.75 |  Val. precision: 0.76 | Val. recall: 0.75\nEpoch: 22 | Epoch Time: 0m 15s\n\tTrain Loss: 0.113 | Train f1: 0.92 | Train precision: 0.93 | Train recall: 0.91\n\t Val. Loss: 0.491 |  Val. f1: 0.76 |  Val. precision: 0.77 | Val. recall: 0.75\nEpoch: 23 | Epoch Time: 0m 15s\n\tTrain Loss: 0.105 | Train f1: 0.93 | Train precision: 0.94 | Train recall: 0.92\n\t Val. Loss: 0.523 |  Val. f1: 0.76 |  Val. precision: 0.78 | Val. recall: 0.74\nEpoch: 24 | Epoch Time: 0m 15s\n\tTrain Loss: 0.099 | Train f1: 0.93 | Train precision: 0.94 | Train recall: 0.92\n\t Val. Loss: 0.471 |  Val. f1: 0.77 |  Val. precision: 0.79 | Val. recall: 0.75\nEpoch: 25 | Epoch Time: 0m 15s\n\tTrain Loss: 0.090 | Train f1: 0.94 | Train precision: 0.94 | Train recall: 0.93\n\t Val. Loss: 0.522 |  Val. f1: 0.75 |  Val. precision: 0.75 | Val. recall: 0.75\nEpoch: 26 | Epoch Time: 0m 15s\n\tTrain Loss: 0.092 | Train f1: 0.94 | Train precision: 0.94 | Train recall: 0.93\n\t Val. Loss: 0.500 |  Val. f1: 0.76 |  Val. precision: 0.77 | Val. recall: 0.76\nEpoch: 27 | Epoch Time: 0m 15s\n\tTrain Loss: 0.081 | Train f1: 0.94 | Train precision: 0.95 | Train recall: 0.94\n\t Val. Loss: 0.550 |  Val. f1: 0.76 |  Val. precision: 0.76 | Val. recall: 0.76\nEpoch: 28 | Epoch Time: 0m 15s\n\tTrain Loss: 0.083 | Train f1: 0.94 | Train precision: 0.95 | Train recall: 0.94\n\t Val. Loss: 0.560 |  Val. f1: 0.76 |  Val. precision: 0.76 | Val. recall: 0.76\nEpoch: 29 | Epoch Time: 0m 15s\n\tTrain Loss: 0.077 | Train f1: 0.95 | Train precision: 0.95 | Train recall: 0.94\n\t Val. Loss: 0.557 |  Val. f1: 0.76 |  Val. precision: 0.76 | Val. recall: 0.75\nEpoch: 30 | Epoch Time: 0m 15s\n\tTrain Loss: 0.074 | Train f1: 0.95 | Train precision: 0.95 | Train recall: 0.94\n\t Val. Loss: 0.566 |  Val. f1: 0.76 |  Val. precision: 0.76 | Val. recall: 0.76\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el mejor modelo entrenado\n",
        "model.load_state_dict(torch.load('{}.pt'.format(model_name)))"
      ],
      "metadata": {
        "id": "27JPQXTOCoYm",
        "execution": {
          "iopub.status.busy": "2024-06-12T08:36:08.242931Z",
          "iopub.execute_input": "2024-06-12T08:36:08.243566Z",
          "iopub.status.idle": "2024-06-12T08:36:08.296523Z",
          "shell.execute_reply.started": "2024-06-12T08:36:08.243531Z",
          "shell.execute_reply": "2024-06-12T08:36:08.295474Z"
        },
        "trusted": true,
        "outputId": "2e439d44-177a-4191-b095-2bdfcbc234f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 77,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<All keys matched successfully>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Limpiar ram de cuda\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "RH4463vvCqg9",
        "execution": {
          "iopub.status.busy": "2024-06-12T08:36:11.03177Z",
          "iopub.execute_input": "2024-06-12T08:36:11.032497Z",
          "iopub.status.idle": "2024-06-12T08:36:11.053055Z",
          "shell.execute_reply.started": "2024-06-12T08:36:11.032464Z",
          "shell.execute_reply": "2024-06-12T08:36:11.051907Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluaci칩n"
      ],
      "metadata": {
        "id": "DYBzB3SlenbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prueba_loss, prueba_precision, prueba_recall, prueba_f1 = evaluate(\n",
        "    model, dataloader_test, model_criterion)\n",
        "\n",
        "print(\n",
        "    f'Test. Loss: {prueba_loss:.3f} |  Test. f1: {prueba_f1:.2f} | Test. precision: {prueba_precision:.2f} | Test. recall: {prueba_recall:.2f}'\n",
        ")"
      ],
      "metadata": {
        "id": "0w69TMqoenba",
        "execution": {
          "iopub.status.busy": "2024-06-12T08:36:13.735833Z",
          "iopub.execute_input": "2024-06-12T08:36:13.736653Z",
          "iopub.status.idle": "2024-06-12T08:36:14.700814Z",
          "shell.execute_reply.started": "2024-06-12T08:36:13.736618Z",
          "shell.execute_reply": "2024-06-12T08:36:14.699835Z"
        },
        "trusted": true,
        "outputId": "49126311-659a-4c83-f45f-e080d8211743"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Test. Loss: 0.472 |  Test. f1: 0.75 | Test. precision: 0.78 | Test. recall: 0.72\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### An치lisis"
      ],
      "metadata": {
        "id": "YxQkQt1Benba"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al comparar 칰nicamente el F1-score, la precisi칩n y el recall entre el modelo experimental y el baseline, se observa que el F1-score aument칩 ligeramente de 0.73 a 0.75 en el modelo experimental, lo que indica una mejora en el equilibrio entre precisi칩n y recall. La precisi칩n tambi칠n experiment칩 un peque침o incremento, pasando de 0.76 a 0.78, lo que sugiere una ligera mejora en la proporci칩n de predicciones correctas entre todas las predicciones realizadas. Sin embargo, aunque el recall aument칩 marginalmente de 0.71 a 0.72, esta mejora es m칤nima y podr칤a no ser lo suficientemente significativa para impactar en la identificaci칩n efectiva de todas las entidades relevantes en los datos. Estos resultados sugieren que, a pesar de algunas mejoras en las m칠tricas, el modelo experimental a칰n no logra superar de manera considerable al baseline en t칠rminos de rendimiento en la tarea de reconocimiento de entidades nombradas."
      ],
      "metadata": {
        "id": "cT-giD-Tenbb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Comparaci칩n de experimentos**"
      ],
      "metadata": {
        "id": "ETvk1QHuC-Gs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "|  Modelo  | f1-score | precision | recall |\n",
        "|----------|----------|-----------|--------|\n",
        "| Baseline |   0.73   |   0.76    |  0.71  |\n",
        "| Modelo 1 |   0.76   |   0.81    |  0.72  |\n",
        "| Modelo 2 |   0.76   |   0.79    |  0.73  |\n",
        "| Modelo 3 |   0.75   |   0.78    |  0.72  |\n",
        "\n",
        "\n",
        "Al analizar los resultados de los cuatro modelos, podemos observar varias tendencias interesantes.\n",
        "\n",
        "En primer lugar, los Modelos 1 y 2 muestran un rendimiento similar en t칠rminos de F1-score, con ambos alcanzando un valor de 0.76. Sin embargo, el Modelo 1 presenta una precisi칩n ligeramente superior (0.81 frente a 0.79) mientras que el Modelo 2 tiene un recall un poco m치s alto (0.73 frente a 0.72), lo que sugiere que el Modelo 1 tiende a tener menos falsos positivos y el Modelo 2 tiende a capturar m치s de las entidades relevantes en los datos.\n",
        "\n",
        "Por otro lado, el Modelo 3 muestra un rendimiento ligeramente inferior en comparaci칩n con los otros modelos, con un F1-score de 0.75. Aunque la precisi칩n es comparable al Modelo 2 (0.78 frente a 0.79), el recall es uno de los m치s bajos entre los modelos (0.72), lo que indica que este modelo podr칤a estar perdiendo algunas entidades relevantes en los datos.\n",
        "\n",
        "En general, aunque todos los modelos muestran mejoras en el rendimiento en comparaci칩n con el baseline, hay diferencias sutiles en c칩mo cada modelo equilibra la precisi칩n y el recall. El Modelo 1 destaca por su alta precisi칩n, mientras que el Modelo 2 muestra un mejor equilibrio entre precisi칩n y recall. El Modelo 3, aunque tiene una precisi칩n similar al Modelo 2, sufre ligeramente en t칠rminos de recall, lo que sugiere que podr칤a necesitar ajustes adicionales para mejorar la identificaci칩n de todas las entidades relevantes."
      ],
      "metadata": {
        "id": "MSvW4wXqDBEX"
      }
    }
  ]
}